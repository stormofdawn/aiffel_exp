{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a016d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d14fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7b6001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49137883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31415</th>\n",
       "      <td>We have five cats - one an elderly cat of 15 y...</td>\n",
       "      <td>Kitty Carbo loaded Junk Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59260</th>\n",
       "      <td>London Cuppa Tea 440 bags is a good everyday b...</td>\n",
       "      <td>Cuppa review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60473</th>\n",
       "      <td>my fiance and i really like engry shot!!  it s...</td>\n",
       "      <td>great enegry!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Taste like it is stale.  Will not order this a...</td>\n",
       "      <td>Does not taste very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7309</th>\n",
       "      <td>Your guess is as good as mine regarding what F...</td>\n",
       "      <td>Festival doesn't tell us what they mean by \"Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86486</th>\n",
       "      <td>This stuff is great -- tastes kind of like tac...</td>\n",
       "      <td>YUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61506</th>\n",
       "      <td>As a standard mayo- this tastes a little odd, ...</td>\n",
       "      <td>Great for sushi making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73315</th>\n",
       "      <td>I was tired of the standard bag of chips and c...</td>\n",
       "      <td>My personal favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>I am enjoying this coffee but the vanilla is a...</td>\n",
       "      <td>Nice strength, maybe too much vanilla?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68893</th>\n",
       "      <td>I use currants a lot. They are difficult to fi...</td>\n",
       "      <td>Currants are a delicious addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74260</th>\n",
       "      <td>THIS PRODUCT IS SO SALTY THAT WE CAN NOT EVEN ...</td>\n",
       "      <td>SALTY SALTY SALTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55126</th>\n",
       "      <td>We have sphynx cats.  The breed often has skin...</td>\n",
       "      <td>life changer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12556</th>\n",
       "      <td>I love this popcorn seasoning and it was cheap...</td>\n",
       "      <td>A Good Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65225</th>\n",
       "      <td>I got these treats the other day hoping that i...</td>\n",
       "      <td>Not satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75688</th>\n",
       "      <td>The flavor of this energy drink is really good...</td>\n",
       "      <td>Sweet pink grapefruit juice flavor, great ener...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "31415  We have five cats - one an elderly cat of 15 y...   \n",
       "59260  London Cuppa Tea 440 bags is a good everyday b...   \n",
       "60473  my fiance and i really like engry shot!!  it s...   \n",
       "334    Taste like it is stale.  Will not order this a...   \n",
       "7309   Your guess is as good as mine regarding what F...   \n",
       "86486  This stuff is great -- tastes kind of like tac...   \n",
       "61506  As a standard mayo- this tastes a little odd, ...   \n",
       "73315  I was tired of the standard bag of chips and c...   \n",
       "1521   I am enjoying this coffee but the vanilla is a...   \n",
       "68893  I use currants a lot. They are difficult to fi...   \n",
       "74260  THIS PRODUCT IS SO SALTY THAT WE CAN NOT EVEN ...   \n",
       "55126  We have sphynx cats.  The breed often has skin...   \n",
       "12556  I love this popcorn seasoning and it was cheap...   \n",
       "65225  I got these treats the other day hoping that i...   \n",
       "75688  The flavor of this energy drink is really good...   \n",
       "\n",
       "                                                 Summary  \n",
       "31415                       Kitty Carbo loaded Junk Food  \n",
       "59260                                       Cuppa review  \n",
       "60473                                      great enegry!  \n",
       "334                             Does not taste very good  \n",
       "7309   Festival doesn't tell us what they mean by \"Fr...  \n",
       "86486                                                YUM  \n",
       "61506                             Great for sushi making  \n",
       "73315                               My personal favorite  \n",
       "1521              Nice strength, maybe too much vanilla?  \n",
       "68893                  Currants are a delicious addition  \n",
       "74260                                  SALTY SALTY SALTY  \n",
       "55126                                       life changer  \n",
       "12556                                       A Good Price  \n",
       "65225                                      Not satisfied  \n",
       "75688  Sweet pink grapefruit juice flavor, great ener...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7173156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00668fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e141703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6abed0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed0b252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "366d0b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af00a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a27d6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1adf4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34bd060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
     ]
    }
   ],
   "source": [
    "clean_summary = []\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a87fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0386af54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efbc210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ddcf83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcwUlEQVR4nO3dfbgWdb3v8fdHUHT7BARxIZgLj5x29qAhKl1ZWe4QH3baOWp6LNBIrtLS9q4Mtp18KK/0tI+W7VIp2aLbNE5mchRDQsjdKRVQEvBhs0Tcgg+gKKCWCX7PH/O7ZViuh2Fg7nvda31e1zXXmvnOb+b+zrplfZ2Z3/xGEYGZmVkZOzU6ATMza14uImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiVhFJr+SmNyX9Obd8eon9HSlpVRW5mpXVt9EJmPVUEbFHbV7SSuALEfHbxmVktuP5TMSsziTtJGmypCckvShphqSBad3Vkm7Ntb1c0lxJuwN3Afvkzmb2adQxmNW4iJjV31eAE4GPAfsALwE/Tuu+Brxf0hmSPgJMBCZExKvAMcAzEbFHmp6pf+pmW/PlLLP6+yLw5YhYBSDpIuA/JX0uIl6T9Dmys46NwFdq7cy6IxcRs/rbD7hN0pu52GZgCLA6Iu6XtAJ4JzCjEQmaFeXLWWb19zRwTET0z027RsRqAEnnAP2AZ4Dzc9t5yG3rdlxEzOrvGuBSSfsBSBos6YQ0/1+B7wKfBT4HnC/p4LTd88A7JO1d/5TN2uciYlZ/PwRmAndL2gjcBxwuqS/wb8DlEfGniFgO/BNwo6R+EfEYcDOwQtLL7p1l3YH8UiozMyvLZyJmZlaai4iZmZXmImJmZqW5iJiZWWm97mHDQYMGRUtLS6PTMDNrGosWLXohIga3t67XFZGWlhYWLlzY6DTMzJqGpKc6WufLWWZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlZar3tifXu0TL6zw3UrLzuujpmYmXUPPhMxM7PSKi0iklZKWiJpsaSFKTZQ0hxJy9PPASkuSVdJapX0sKRRuf1MSO2XS5qQix+S9t+atlWVx2NmZlurx5nIxyPi4IgYnZYnA3MjYiQwNy0DHAOMTNMk4GrIig5wIXA4cBhwYa3wpDZn5bYbV/3hmJlZTSMuZ50ATE/z04ETc/EbInMf0F/SUOBoYE5ErIuIl4A5wLi0bq+IuC+yF8XfkNuXmZnVQdVFJIC7JS2SNCnFhkTEs2n+OWBImh8GPJ3bdlWKdRZf1U78bSRNkrRQ0sK1a9duz/GYmVlO1b2zjoiI1ZLeCcyR9Fh+ZUSEpKg4ByJiKjAVYPTo0ZV/nplZb1HpmUhErE4/1wC3kd3TeD5diiL9XJOarwb2zW0+PMU6iw9vJ25mZnVSWRGRtLukPWvzwFhgKTATqPWwmgDcnuZnAuNTL60xwPp02Ws2MFbSgHRDfSwwO63bIGlM6pU1PrcvMzOrgyovZw0Bbku9bvsCP4+I30haAMyQNBF4CjgltZ8FHAu0Aq8BZwJExDpJ3wEWpHaXRMS6NH82cD2wG3BXmszMrE4qKyIRsQI4qJ34i8BR7cQDOKeDfU0DprUTXwi8b7uTNTOzUvzEupmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlplRcRSX0kPSTpjrQ8QtL9klol/ULSLineLy23pvUtuX1MSfHHJR2di49LsVZJk6s+FjMz21o9zkTOAx7NLV8OXBkRBwAvARNTfCLwUopfmdoh6UDgVOC9wDjgJ6kw9QF+DBwDHAicltqamVmdVFpEJA0HjgN+lpYFfAL4ZWoyHTgxzZ+Qlknrj0rtTwBuiYjXI+JJoBU4LE2tEbEiIv4K3JLamplZnVR9JvID4HzgzbT8DuDliNiUllcBw9L8MOBpgLR+fWr/VrzNNh3F30bSJEkLJS1cu3btdh6SmZnVVFZEJB0PrImIRVV9RlERMTUiRkfE6MGDBzc6HTOzHqNvhfv+MPApSccCuwJ7AT8E+kvqm842hgOrU/vVwL7AKkl9gb2BF3Pxmvw2HcXNzKwOKjsTiYgpETE8IlrIbozfExGnA/OAk1KzCcDtaX5mWiatvyciIsVPTb23RgAjgQeABcDI1Ntrl/QZM6s6HjMze7sqz0Q68k3gFknfBR4Crkvx64AbJbUC68iKAhGxTNIM4BFgE3BORGwGkPRlYDbQB5gWEcvqeiRmZr1cXYpIRMwH5qf5FWQ9q9q2+QtwcgfbXwpc2k58FjBrB6ZqZmbbwE+sm5lZaV0WEUknS9ozzX9L0q8kjao+NTMz6+6KnIn8z4jYKOkI4O/I7l1cXW1aZmbWDIoUkc3p53HA1Ii4E9ilupTMzKxZFCkiqyVdC3wGmCWpX8HtzMyshytSDE4h60Z7dES8DAwEvlFlUmZm1hy6LCIR8RqwBjgihTYBy6tMyszMmkOR3lkXkj0gOCWFdgb+rcqkzMysORS5nPVp4FPAqwAR8QywZ5VJmZlZcyhSRP6axrAKAEm7V5uSmZk1iyJFZEbqndVf0lnAb4GfVpuWmZk1gy7HzoqIf5b0SWAD8G7g2xExp/LMzMys2ys0AGMqGi4cZma2lQ6LiKSNpPsgbVcBERF7VZaVmZk1hQ6LSES4B5aZmXWq0OWsNGrvEWRnJr+PiIcqzcrMzJpCkYcNvw1MB94BDAKul/StqhMzM7Pur8iZyOnAQenNg0i6DFgMfLfCvMzMrAkUeU7kGWDX3HI/YHU16ZiZWTMpciayHlgmaQ7ZPZFPAg9IugogIs6tMD8zM+vGihSR29JUM7+aVMzMrNkUeWJ9ej0SMTOz5lOkd9bxkh6StE7SBkkbJW2oR3JmZta9Fbmc9QPgvwFL0mi+ZmZmQLHeWU8DS11AzMysrSJnIucDsyT9Dni9FoyIKyrLyszMmkKRInIp8ArZsyK7VJuOmZk1kyJFZJ+IeF/lmZiZWdMpck9klqSxlWdiZmZNp0gR+RLwG0l/dhdfMzPLK/Kwod8rYmZm7Sr6PpEBwEhyAzFGxL1VJWVmZs2hyBPrXwDuBWYDF6efFxXYbldJD0j6k6Rlki5O8RGS7pfUKukXknZJ8X5puTWtb8nta0qKPy7p6Fx8XIq1Spq8jcduZmbbqcg9kfOAQ4GnIuLjwAeBlwts9zrwiYg4CDgYGCdpDHA5cGVEHAC8BExM7ScCL6X4lakdkg4ETgXeC4wDfiKpj6Q+wI+BY4ADgdNSWzMzq5MiReQvuRdS9YuIx4B3d7VRZF5JizunKYBPAL9M8enAiWn+hLRMWn+UJKX4LRHxekQ8CbQCh6WpNSJWRMRfgVtSWzMzq5MiRWSVpP7Ar4E5km4Hniqy83TGsBhYA8wBngBejohNtX0Dw9L8MLIhVkjr15O9kveteJttOoq3l8ckSQslLVy7dm2R1M3MrIAivbM+nWYvkjQP2Bv4TZGdR8Rm4OBUhG4D/rZkntslIqYCUwFGjx7tMcDMzHaQIjfW/4ukfrVFoAX4m235kIh4GZgHfAjoL6lWvIaz5VW7q4F902f2JStWL+bjbbbpKG5mZnVS5HLWrcBmSQeQ/d/8vsDPu9pI0uB0BoKk3cheq/soWTE5KTWbANye5memZdL6e9LIwTOBU1PvrRFkXY0fABYAI1Nvr13Ibr7PLHA8Zma2gxR5TuTNiNgk6dPAjyLiR5IeKrDdUGB66kW1EzAjIu6Q9Ahwi6TvAg8B16X21wE3SmoF1pEVBSJimaQZwCPAJuCcdJkMSV8m63LcB5gWEcsKHreZme0ARYrIG5JOIztL+PsU27mrjSLiYbLuwG3jK8h6VrWN/wU4uYN9XUo2mnDb+CxgVle5mJlZNYpczjqT7F7GpRHxZLqkdGO1aZmZWTMo0jvrEeDc3PKTpAcBzcysdytyJmJmZtYuFxEzMyutwyIi6cb087z6pWNmZs2kszORQyTtA3xe0gBJA/NTvRI0M7Puq7Mb69cAc4H9gUVkT6vXRIqbmVkv1uGZSERcFRHvIXuIb/+IGJGbXEDMzKxQF98vSToI+EgK3ZseJDQzs16uyACM5wI3Ae9M002SvlJ1YmZm1v0VGfbkC8DhEfEqgKTLgT8CP6oyMTMz6/6KPCciYHNueTNb32Q3M7NeqsiZyL8C90u6LS2fyJaRd83MrBcrcmP9CknzgSNS6MyIKDIUvJmZ9XBFzkSIiAeBByvOxczMmozHzjIzs9JcRMzMrLROi4ikPpLm1SsZMzNrLp0WkfQu8zcl7V2nfMzMrIkUubH+CrBE0hzg1VowIs7teJPep2XynZ2uX3nZcXXKxMysfooUkV+lyczMbCtFnhOZLmk34F0R8XgdcjIzsyZRZADGvwcWA79JywdLmllxXmZm1gSKdPG9CDgMeBkgIhbjF1KZmRnFisgbEbG+TezNKpIxM7PmUuTG+jJJ/wPoI2kkcC7wh2rTMjOzZlDkTOQrwHuB14GbgQ3AVyvMyczMmkSR3lmvARekl1FFRGysPi0zM2sGRXpnHSppCfAw2UOHf5J0SPWpmZlZd1fknsh1wNkR8e8Ako4ge1HVB6pMzMzMur8i90Q21woIQET8HthUXUpmZtYsOiwikkZJGgX8TtK1ko6U9DFJPwHmd7VjSftKmifpEUnLJJ2X4gMlzZG0PP0ckOKSdJWkVkkPp8+u7WtCar9c0oRc/BBJS9I2V0nyu9/NzOqos8tZ/7vN8oW5+Siw703A1yLiQUl7AovSII5nAHMj4jJJk4HJwDeBY4CRaTocuBo4XNLA9Nmj0+cukjQzIl5Kbc4C7gdmAeOAuwrkZmZmO0CHRSQiPr49O46IZ4Fn0/xGSY8Cw4ATgCNTs+lkZzXfTPEbIiKA+yT1lzQ0tZ0TEesAUiEal977vldE3JfiNwAn4iJiZlY3Xd5Yl9QfGA+05Ntvy1DwklqAD5KdMQxJBQbgOWBImh8GPJ3bbFWKdRZf1U68vc+fBEwCeNe73lU0bTMz60KR3lmzgPuAJZQY7kTSHsCtwFcjYkP+tkVEhKQil8a2S0RMBaYCjB49uvLPMzPrLYoUkV0j4h/L7FzSzmQF5KaIqL2T5HlJQyPi2XS5ak2Krwb2zW0+PMVWs+XyVy0+P8WHt9PezMzqpEgX3xslnSVpaOpZNTDd7O5U6il1HfBoRFyRWzUTqPWwmgDcnouPT720xgDr02Wv2cBYSQNST66xwOy0boOkMemzxuf2ZWZmdVDkTOSvwPeBC9jSKyvoejj4DwOfI3vKfXGK/RNwGTBD0kTgKeCUtG4WcCzQCrwGnAkQEeskfQdYkNpdUrvJDpwNXA/sRnZD3TfVzczqqEgR+RpwQES8sC07Tg8ldvTcxlHttA/gnA72NQ2Y1k58IfC+bcnLzMx2nCKXs2pnBmZmZlspcibyKrBY0jyy4eCBbevia2ZmPVORIvLrNJmZmW2lyPtEptcjETMzaz5Fnlh/knbGyoqIrnpnmZlZD1fkctbo3PyuwMlAl8+JmJlZz9dl76yIeDE3rY6IHwDHVZ+amZl1d0UuZ43KLe5EdmZS5AzGzMx6uCLFIP9ekU3ASrY8ZW5mZr1Ykd5Z2/VeETMz67mKXM7qB/x33v4+kUuqS8vMzJpBkctZtwPrgUXknlg3MzMrUkSGR8S4yjMxM7OmU2QAxj9Ien/lmZiZWdMpciZyBHBGenL9dbLh3SMiPlBpZmZm1u0VKSLHVJ6FmZk1pSJdfJ+qRyJmZtZ8itwTMTMza5eLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZlVZZEZE0TdIaSUtzsYGS5khann4OSHFJukpSq6SHJY3KbTMhtV8uaUIufoikJWmbqySpqmMxM7P2VXkmcj3Q9t3sk4G5ETESmJuWIXvx1cg0TQKuhqzoABcChwOHARfWCk9qc1ZuO78H3sysziorIhFxL7CuTfgEYHqanw6cmIvfEJn7gP6ShgJHA3MiYl1EvATMAcaldXtFxH0REcANuX2ZmVmd1PueyJCIeDbNPwcMSfPDgKdz7ValWGfxVe3E2yVpkqSFkhauXbt2+47AzMze0rAb6+kMIur0WVMjYnREjB48eHA9PtLMrFeodxF5Pl2KIv1ck+KrgX1z7YanWGfx4e3EzcysjupdRGYCtR5WE4Dbc/HxqZfWGGB9uuw1GxgraUC6oT4WmJ3WbZA0JvXKGp/bl5mZ1UnfqnYs6WbgSGCQpFVkvawuA2ZImgg8BZySms8CjgVagdeAMwEiYp2k7wALUrtLIqJ2s/5ssh5guwF3pcnMzOqosiISEad1sOqodtoGcE4H+5kGTGsnvhB43/bkaGZm28dPrJuZWWkuImZmVpqLiJmZleYiYmZmpVV2Y9221jL5zk7Xr7zsuDplYma24/hMxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PS/HrcbqKz1+f61blm1l35TMTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0tzFtwl01v0X3AXYzBrHZyJmZlZa05+JSBoH/BDoA/wsIi5rcEp15wcVzaxRmrqISOoD/Bj4JLAKWCBpZkQ80tjMug9fCjOzKjV1EQEOA1ojYgWApFuAEwAXkYK6KjKdcQEys2YvIsOAp3PLq4DD2zaSNAmYlBZfkfR4ic8aBLxQYrvuZocdhy7fEXsppSd8Fz3hGKBnHEdPOAao9jj262hFsxeRQiJiKjB1e/YhaWFEjN5BKTVMTzgOH0P30ROOoyccAzTuOJq9d9ZqYN/c8vAUMzOzOmj2IrIAGClphKRdgFOBmQ3Oycys12jqy1kRsUnSl4HZZF18p0XEsoo+brsuh3UjPeE4fAzdR084jp5wDNCg41BENOJzzcysB2j2y1lmZtZALiJmZlaai0gBksZJelxSq6TJjc6nI5L2lTRP0iOSlkk6L8UHSpojaXn6OSDFJemqdFwPSxrV2CPYQlIfSQ9JuiMtj5B0f8r1F6kjBZL6peXWtL6loYnnSOov6ZeSHpP0qKQPNdt3Iekf0n9LSyXdLGnXZvguJE2TtEbS0lxsm3/3kiak9sslTegGx/D99N/Tw5Juk9Q/t25KOobHJR2di1f79ysiPHUykd2wfwLYH9gF+BNwYKPz6iDXocCoNL8n8B/AgcD/Aian+GTg8jR/LHAXIGAMcH+jjyF3LP8I/By4Iy3PAE5N89cAX0rzZwPXpPlTgV80OvfcMUwHvpDmdwH6N9N3QfYw75PAbrnv4Ixm+C6AjwKjgKW52Db97oGBwIr0c0CaH9DgYxgL9E3zl+eO4cD0t6kfMCL9zepTj79fDf2PtBkm4EPA7NzyFGBKo/MqmPvtZOOKPQ4MTbGhwONp/lrgtFz7t9o1OO/hwFzgE8Ad6R/3C7l/PG99J2Q98z6U5vumduoGx7B3+gOsNvGm+S7YMiLEwPS7vQM4ulm+C6ClzR/gbfrdA6cB1+biW7VrxDG0Wfdp4KY0v9Xfpdp3UY+/X76c1bX2hlYZ1qBcCkuXEj4I3A8MiYhn06rngCFpvrse2w+A84E30/I7gJcjYlNazuf51jGk9etT+0YbAawF/jVdlvuZpN1pou8iIlYD/wz8J/As2e92Ec33XdRs6+++230nbXye7AwKGngMLiI9kKQ9gFuBr0bEhvy6yP53pNv265Z0PLAmIhY1Opft1JfsUsTVEfFB4FWySyhvaYLvYgDZgKYjgH2A3YFxDU1qB+nuv/uuSLoA2ATc1OhcXES61lRDq0jamayA3BQRv0rh5yUNTeuHAmtSvDse24eBT0laCdxCdknrh0B/SbWHY/N5vnUMaf3ewIv1TLgDq4BVEXF/Wv4lWVFppu/i74AnI2JtRLwB/Irs+2m276JmW3/33fE7QdIZwPHA6akYQgOPwUWka00ztIokAdcBj0bEFblVM4Faz5IJZPdKavHxqXfKGGB97nS/ISJiSkQMj4gWst/1PRFxOjAPOCk1a3sMtWM7KbVv+P9hRsRzwNOS3p1CR5G9oqBpvguyy1hjJP1N+m+rdgxN9V3kbOvvfjYwVtKAdFY2NsUaRtlL+M4HPhURr+VWzQROTT3kRgAjgQeox9+vet4kataJrPfGf5D1crig0fl0kucRZKfoDwOL03Qs2XXpucBy4LfAwNReZC/1egJYAoxu9DG0OZ4j2dI7a//0j6IV+D9AvxTfNS23pvX7NzrvXP4HAwvT9/Frsh4+TfVdABcDjwFLgRvJev90++8CuJnsPs4bZGeFE8v87snuO7Sm6cxucAytZPc4av++r8m1vyAdw+PAMbl4pX+/POyJmZmV5stZZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4j1WJJeqWCfB0s6Nrd8kaSvb8f+Tk4j/M7bMRmWzmOlpEGNzMGak4uI2bY5mKzf/Y4yETgrIj6+A/dpVjcuItYrSPqGpAXpPQwXp1hLOgv4aXpnxt2SdkvrDk1tF6d3OCxNT/xeAnwmxT+Tdn+gpPmSVkg6t4PPP03SkrSfy1Ps22QPiF4n6ftt2g+VdG/6nKWSPpLiV0tamPK9ONd+paTvpfYLJY2SNFvSE5K+mNocmfZ5Z3q/xDWS3vY3QNJnJT2Q9nWtsne79JF0fcpliaR/2M6vxHqKRj8R68lTVRPwSvo5FphK9mTyTmRDmn+UbJjtTcDBqd0M4LNpfilbhjW/jDQcN9n7NP4l9xkXAX8ge5J7ENlYUTu3yWMfsiFEBpMNzHgPcGJaN592nk4HvkZ6upjsnRB7pvmBudh84ANpeSVb3utxJdlT8numz3w+xY8E/kL2xHkfYA5wUm77QcB7gP9bOwbgJ8B44BBgTi6//o3+fj11j8lnItYbjE3TQ8CDwN+SjS0E2QCDi9P8IqBF2dvi9oyIP6b4z7vY/50R8XpEvEA2qN+QNusPBeZHNpBhbeTVj3axzwXAmZIuAt4fERtT/BRJD6ZjeS/Zy4hqamMiLSF7sdLGiFgLvK4tb8B7ICJWRMRmsmE1jmjzuUeRFYwFkhan5f3JXsi0v6QfpfGbNmBG9n9FZj2dgO9FxLVbBbN3rryeC20Gdiux/7b72O5/VxFxr6SPAscB10u6Avh34OvAoRHxkqTrycarapvHm21yejOXU9txjtouC5geEVPa5iTpILKXUn0ROIVsXCnr5XwmYr3BbODzyt6zgqRhkt7ZUeOIeBnYKOnwFDo1t3oj2WWibfEA8DFJgyT1IXtj3u8620DSfmSXoX4K/IxsGPm9yN5Lsl7SEOCYbcwD4LA0outOwGeA37dZPxc4qfb7UfZe8v1Sz62dIuJW4FspHzOfiVjPFxF3S3oP8MdsRHNeAT5LdtbQkYnATyW9SfYHf32KzwMmp0s93yv4+c9Kmpy2Fdnlr9u72OxI4BuS3kj5jo+IJyU9RDaq7tPA/yvy+W0sAP4FOCDlc1ubXB+R9C3g7lRo3gDOAf5M9pbG2v94vu1MxXonj+Jr1g5Je0TEK2l+Mtm7uc9rcFrbRdKRwNcj4vgGp2I9iM9EzNp3nKQpZP9GniLrlWVmbfhMxMzMSvONdTMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMr7f8Do1dsKbWvtPIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgM0lEQVR4nO3de7hVdb3v8fdHUrPShCQOcmmhkWXuQl1e9rPJaLtV1E7oPmXQSdBMMjXtZCVWJ90WT3SzNruyMEksL7G3mmzFkDya3VQWyuHiJZaIR9gIJCp4iQS/54/xWzpcrLUYjLXmnMw5P6/nmc8c4ztu3+F8WF/H+P3GbygiMDMzK2OXWidgZmb1y0XEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMx6IGm0pD9KelbSBkl/kHRYrfMy21m8rtYJmO2sJO0F3AJ8GpgN7Aa8D9hcy7x2hCQBioiXa52LNSZfiZh17x0AEXFdRGyNiBcj4vaIWCzpEkm/6FhRUoukkPS6NH+XpK+nq5jnJP2npLdIukbSRkkLJLXktg9JZ0taLmmTpK9J2j9tv1HSbEm7pXX7S7pF0npJT6fpobl93SVpqqQ/AC8AF0hamD8xSZ+TdHNF/+tZU3ARMeven4GtkmZJOl5S/x3cfjxwKjAE2B/4E/AzYADwEHBxp/WPAw4FjgS+CMwAPg4MAw4CJqT1dkn7eRswHHgR+EGnfZ0KTAb2BKYDIyS9q9Pyq3fwfMy24SJi1o2I2AiMBgK4AlgvaY6kQQV38bOIeDQingVuAx6NiN9ExBbg34GDO63/rYjYGBHLgKXA7RGxIrf9wSmvpyLihoh4ISI2AVOB93fa11URsSwitkTEZuCXZAUJSe8GWshu1Zn1iouIWQ8i4qGIOC0ihpJdDewLfL/g5mtz0y92Mf+mMutLeoOkn0h6XNJG4G5gb0n9cus/0Wnfs4CPpTaSU4HZqbiY9YqLiFlBEfEwcBVZMXkeeENu8X+rYioXAAcAR0TEXsBRKa7cOq8Znjsi7gH+RtYx4GPAz6uQpzUBFxGzbkh6p6QLOhqtJQ0ja5e4B1gEHCVpuKQ3AxdVMbU9ya5MnpE0gG3bVrpzNVnbyUsR8ftKJWfNxUXErHubgCOAeyU9T1Y8lgIXRMR8snaGxcBCqtu+8H1gD+AvKadfF9zu52RXUb/Y3opmRckvpTJrDpL2ANYBh0TE8lrnY43BVyJmzePTwAIXEOtLfmLdrAlIWknW8H5SbTOxRuPbWWZmVlrFbmdJGibpTkkPSlom6fwUHyBpfhreYX7HU8DKTJfULmmxpENy+5qU1l8uaVIufqikJWmb6akPvJmZVUnFrkQkDQYGR8T9kvYk68FyEnAasCEipkmaAvSPiAslnQB8BjiBrEfMv0bEEakLYxvQStb3fSFwaEQ8Lek+4DzgXmAuMD0ibuspr3322SdaWlr6/oTNzBrYwoUL/xIRAzvHK9YmEhFrgDVpepOkh8jGEBoHjEmrzQLuAi5M8asjq2r3SNo7FaIxwPyI2AAgaT4wVtJdwF7pISokXU1WpHosIi0tLbS1tfXZeZqZNQNJj3cVr0rvrDRa6cFkVwyDUoEBeBLoGIdoCK8dqmFVivUUX9VFvKvjT5bUJqlt/fr1vTsZMzN7RcWLiKQ3ATcAn00D2r0iXXVUvGU/ImZERGtEtA4cuM3VmJmZlVTRIiJpV7ICck1E3JjCa9Ntqo52k3UpvppsyOsOQ1Osp/jQLuJmZlYlleydJeBK4KGIuCy3aA7Q0cNqEnBzLj4x9dI6Eng23faaBxybXsTTHzgWmJeWbZR0ZDrWxNy+zMysCir5sOE/kA05vUTSohT7EjANmC3pDOBx4JS0bC5Zz6x2srexnQ4QERskfQ1YkNa7tKORHTibbFTVPcga1HtsVDczs77VdA8btra2hntnmZntGEkLI6K1c9xjZ5mZWWkuImZmVpqLiJmZleZRfPtQy5Rbu122ctqJVczEzKw6fCViZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpFSsikmZKWidpaS72S0mL0mdlx7vXJbVIejG37Me5bQ6VtERSu6TpkpTiAyTNl7Q8ffev1LmYmVnXKnklchUwNh+IiI9GxKiIGAXcANyYW/xox7KIOCsXvxw4ExiZPh37nALcEREjgTvSvJmZVVHFikhE3A1s6GpZupo4Bbiup31IGgzsFRH3REQAVwMnpcXjgFlpelYubmZmVVKrNpH3AWsjYnkuNkLSA5J+K+l9KTYEWJVbZ1WKAQyKiDVp+klgUHcHkzRZUpuktvXr1/fRKZiZWa2KyAReexWyBhgeEQcDnwOulbRX0Z2lq5ToYfmMiGiNiNaBAweWzdnMzDqp+jvWJb0O+Gfg0I5YRGwGNqfphZIeBd4BrAaG5jYfmmIAayUNjog16bbXumrkb2Zmr6rFlcg/AQ9HxCu3qSQNlNQvTe9H1oC+It2u2ijpyNSOMhG4OW02B5iUpifl4mZmViWV7OJ7HfAn4ABJqySdkRaNZ9sG9aOAxanL738AZ0VER6P82cBPgXbgUeC2FJ8GHCNpOVlhmlapczEzs65V7HZWREzoJn5aF7EbyLr8drV+G3BQF/GngKN7l6WZmfWGn1g3M7PSXETMzKw0FxEzMyut6l18m1XLlFt7XL5y2olVysTMrO/4SsTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9Iq+Y71mZLWSVqai10iabWkRelzQm7ZRZLaJT0i6bhcfGyKtUuakouPkHRviv9S0m6VOhczM+taJa9ErgLGdhH/XkSMSp+5AJIOBMYD707b/EhSP0n9gB8CxwMHAhPSugDfTPt6O/A0cEYFz8XMzLpQsSISEXcDGwquPg64PiI2R8RjQDtwePq0R8SKiPgbcD0wTpKAfwT+I20/CzipL/M3M7Ptq0WbyLmSFqfbXf1TbAjwRG6dVSnWXfwtwDMRsaVTvEuSJktqk9S2fv36vjoPM7OmV+0icjmwPzAKWAN8txoHjYgZEdEaEa0DBw6sxiHNzJpCVd+xHhFrO6YlXQHckmZXA8Nyqw5NMbqJPwXsLel16Wokv76ZmVVJVa9EJA3OzZ4MdPTcmgOMl7S7pBHASOA+YAEwMvXE2o2s8X1ORARwJ/DhtP0k4OZqnIOZmb2qYlcikq4DxgD7SFoFXAyMkTQKCGAl8CmAiFgmaTbwILAFOCcitqb9nAvMA/oBMyNiWTrEhcD1kr4OPABcWalzMTOzrlWsiETEhC7C3f6hj4ipwNQu4nOBuV3EV5D13jIzsxrxE+tmZlbadouIpI9I2jNNf0XSjZIOqXxqZma2sytyJfK/I2KTpNHAP5Hdkrq8smmZmVk9KFJEtqbvE4EZEXEr4HGqzMysUBFZLeknwEeBuZJ2L7idmZk1uCLF4BSyLrbHRcQzwADgC5VMyszM6sN2u/hGxAuS1gGjgeVkz3Esr3Ri9qqWKbf2uHzltBOrlImZ2WsV6Z11MdmDfRel0K7ALyqZlJmZ1Ycit7NOBj4EPA8QEf8F7FnJpMzMrD4UKSJ/S2NVBYCkN1Y2JTMzqxdFisjs1Dtrb0lnAr8BrqhsWmZmVg+KNKx/R9IxwEbgAOCrETG/4pmZmdlOr9AAjKlouHCYmdlrdFtEJG0itYN0XgREROxVsazMzKwudFtEIsI9sMzMrEeFbmelUXtHk12Z/D4iHqhoVmZmVheKPGz4VWAW8BZgH+AqSV+pdGJmZrbzK3Il8j+B90bEXwEkTQMWAV+vYF5mZlYHijwn8l/A63PzuwOrt7eRpJmS1klamot9W9LDkhZLuknS3ineIulFSYvS58e5bQ6VtERSu6TpkpTiAyTNl7Q8ffcveM5mZtZHihSRZ4Flkq6S9DNgKfBM+oM+vYftrgLGdorNBw6KiPcAf+bV8bgAHo2IUelzVi5+OXAmMDJ9OvY5BbgjIkYCd6R5MzOroiK3s25Knw53FdlxRNwtqaVT7Pbc7D3Ah3vah6TBwF4RcU+avxo4CbgNGAeMSavOSnldWCQ3MzPrG0WeWJ9VoWN/Avhlbn6EpAfInoz/SkT8DhgCrMqtsyrFAAZFxJo0/SQwqLsDSZoMTAYYPnx432RvZmaFemd9UNIDkjZI2ihpk6SNvTmopC+TvZfkmhRaAwyPiIOBzwHXSir8MGN+gMhuls+IiNaIaB04cGAvMjczs7wit7O+D/wzsCT9se4VSacBHwSO7thfRGwGNqfphZIeBd5B1oA/NLf5UF5t1F8raXBErEm3vdb1NjczM9sxRRrWnwCW9lEBGQt8EfhQRLyQiw+U1C9N70fWgL4i3a7aKOnI1CtrInBz2mwOMClNT8rFzcysSopciXwRmCvpt6SrBYCIuKynjSRdR9bwvY+kVcDFZL2xdgfmp56696SeWEcBl0p6CXgZOCsiNqRdnU3W02sPsgb121J8Gtkw9WcAj5O9C97MzKqoSBGZCjxH9qzIbkV3HBETughf2c26NwA3dLOsDTioi/hTwNFF8zEzs75XpIjsGxHb/BE3MzMr0iYyV9KxFc/EzMzqTpEi8mng12lYkj7p4mtmZo2hyMOGfq+ImZl1qej7RPqTdbt9ZSDGiLi7UkmZmVl92G4RkfRJ4HyyB/0WAUcCfwL+saKZmZnZTq9Im8j5wGHA4xHxAeBg4JlKJmVmZvWhSBH5a+6FVLtHxMPAAZVNy8zM6kGRNpFV6eVRvyJ70vxpsifEzcysyRXpnXVymrxE0p3Am4FfVzQrMzOrC0WGgt9f0u4ds0AL8IZKJmVmZvWhSJvIDcBWSW8HZgDDgGsrmpWZmdWFIkXk5YjYApwM/FtEfAEYXNm0zMysHhQpIi9JmkD2zo5bUmzXyqVkZmb1okgROR34e2BqRDwmaQTw88qmZWZm9aBI76wHgfNy848B36xkUmZmVh+KXImYmZl1yUXEzMxK67aISPp5+j6/7M4lzZS0TtLSXGyApPmSlqfv/ikuSdMltUtaLOmQ3DaT0vrLJU3KxQ+VtCRtM13pxe1mZlYdPbWJHCppX+ATkq4me9DwFRGxocD+rwJ+AFydi00B7oiIaZKmpPkLgePJhpsfCRwBXA4cIWkAcDHQCgSwUNKciHg6rXMmcC8wFxgL3FYgr4bSMuXWHpevnHZilTIxs2bT0+2sHwN3AO8EFnb6tBXZeXrnSOdiMw6YlaZnASfl4ldH5h5gb0mDgeOA+RGxIRWO+cDYtGyviLgnIoKsUJ2EmZlVTbdFJCKmR8S7gJkRsV9EjMh99uvFMQdFxJo0/SQwKE0PAZ7IrbcqxXqKr+oivg1JkyW1SWpbv359L1I3M7O8Il18Py3pvcD7UujuiFjcFwePiJAUfbGv7RxnBtmQLbS2tlb8eGZmzaLIAIznAdcAb02fayR9phfHXJtuRZG+16X4arJxuToMTbGe4kO7iJuZWZUU6eL7SeCIiPhqRHyV7PW4Z/bimHPIhlAhfd+ci09MvbSOBJ5Nt73mAcdK6p96ch0LzEvLNko6MvXKmpjbl5mZVUGRl1IJ2Jqb30qnnlrdbihdB4wB9pG0iqyX1TRgtqQzyF5udUpafS5wAtAOvEA23AoRsUHS14AFab1Lcz3DzibrAbYHWa+spuuZZWZWS0WKyM+AeyXdlOZPAq4ssvOImNDNoqO7WDeAc7rZz0xgZhfxNuCgIrmYmVnfK9Kwfpmku4DRKXR6RDxQ0azMzKwuFLkSISLuB+6vcC5mZlZnPHaWmZmV5iJiZmal9VhEJPWTdGe1kjEzs/rSYxGJiK3Ay5LeXKV8zMysjhRpWH8OWCJpPvB8RzAizut+k8a0vdFyzcyaTZEicmP6mJmZvUaR50RmSdoDGB4Rj1QhJzMzqxNFBmD878Ai4NdpfpSkORXOy8zM6kCRLr6XAIcDzwBExCKgN+8TMTOzBlGkiLwUEc92ir1ciWTMzKy+FGlYXybpY0A/SSOB84A/VjYtMzOrB0WuRD4DvBvYDFwHbAQ+W8GczMysThTpnfUC8GVJ38xmY1Pl0zIzs3pQpHfWYZKWAIvJHjr8v5IOrXxqZma2syvSJnIlcHZE/A5A0miyF1W9p5KJmZnZzq9Im8jWjgICEBG/B7ZULiUzM6sX3RYRSYdIOgT4raSfSBoj6f2SfgTcVfaAkg6QtCj32Sjps5IukbQ6Fz8ht81FktolPSLpuFx8bIq1S5pSNiczMyunp9tZ3+00f3FuOsoeMA2dMgqyoeaB1cBNwOnA9yLiO/n1JR0IjCfrIbYv8BtJ70iLfwgcA6wCFkiaExEPls3NzMx2TLdFJCI+UIXjHw08GhGPS+punXHA9RGxGXhMUjvZE/QA7RGxAkDS9WldFxEzsyrZbsO6pL2BiUBLfv0+Ggp+PNmzJx3OlTQRaAMuiIingSHAPbl1VqUYwBOd4kd0dRBJk4HJAMOHD++DtM3MDIo1rM8lKyBLgIW5T69I2g34EPDvKXQ5sD/Zra41bHs7rbSImBERrRHROnDgwL7arZlZ0yvSxff1EfG5Chz7eOD+iFgL0PENIOkK4JY0uxoYlttuaIrRQ9zMzKqgyJXIzyWdKWmwpAEdnz449gRyt7IkDc4tOxlYmqbnAOMl7S5pBDASuA9YAIyUNCJd1YxP65qZWZUUuRL5G/Bt4Mu82isr6MVw8JLeSNar6lO58LckjUr7XtmxLCKWSZpN1mC+BTgnvfsdSecC84B+wMyIWFY2JzMz23FFisgFwNsj4i99ddCIeB54S6fYqT2sPxWY2kV8LlmbjZW0vffGr5x2YpUyMbN6VOR2VjvwQqUTMTOz+lPkSuR5YJGkO8mGgwf6rIuvmZnVsSJF5FfpY2Zm9hpF3icyqxqJmJlZ/SnyxPpjdDFWVkSU7p1lZmaNocjtrNbc9OuBjwB98ZyImZnVue32zoqIp3Kf1RHxfcD9Ps3MrNDtrENys7uQXZkUuYIxM7MGV6QY5AdC3EL2NPkpFcnGzMzqSpHeWdV4r4iZmdWhIrezdgf+B9u+T+TSyqVlZmb1oMjtrJuBZ8neIbJ5O+uamVkTKVJEhkbE2IpnYmZmdafIAIx/lPR3Fc/EzMzqTpErkdHAaenJ9c2AgIiI91Q0MzMz2+kVKSLHVzwLMzOrS0W6+D5ejUTMzKz+FGkTMTMz61LNioiklZKWSFokqS3FBkiaL2l5+u6f4pI0XVK7pMX5oVgkTUrrL5c0qVbnY2bWjGp9JfKBiBgVER0jBU8B7oiIkcAdaR6ydpmR6TMZuByyogNcDBwBHA5c3FF4zMys8mpdRDobB3S8BGsWcFIufnVk7gH2ljQYOA6YHxEbIuJpYD7gZ1rMzKqklkUkgNslLZQ0OcUGRcSaNP0kMChNDwGeyG27KsW6i7+GpMmS2iS1rV+/vi/PwcysqdVySPfREbFa0luB+ZIezi+MiJC0zRsVy4iIGcAMgNbW1j7Zp5mZ1fBKJCJWp+91wE1kbRpr020q0ve6tPpqYFhu86Ep1l3czMyqoCZFRNIbJe3ZMQ0cCywF5gAdPawmkQ3+SIpPTL20jgSeTbe95gHHSuqfGtSPTTEzM6uCWt3OGgTcJKkjh2sj4teSFgCzJZ0BPM6rL7+aC5wAtAMvAKcDRMQGSV8DFqT1Lo2IDdU7DTOz5laTIhIRK4D3dhF/Cji6i3gA53Szr5nAzL7O0czMts/vSrcetUy5tcflK6edWKVMzGxntLM9J2JmZnXERcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9L8PhGrGL+LxKzx+UrEzMxKq3oRkTRM0p2SHpS0TNL5KX6JpNWSFqXPCbltLpLULukRScfl4mNTrF3SlGqfi5lZs6vF7awtwAURcb+kPYGFkuanZd+LiO/kV5Z0IDAeeDewL/AbSe9Ii38IHAOsAhZImhMRD1blLMzMrPpFJCLWAGvS9CZJDwFDethkHHB9RGwGHpPUDhyelrVHxAoASdendV1EzMyqpKZtIpJagIOBe1PoXEmLJc2U1D/FhgBP5DZblWLdxbs6zmRJbZLa1q9f35enYGbW1GpWRCS9CbgB+GxEbAQuB/YHRpFdqXy3r44VETMiojUiWgcOHNhXuzUza3o16eIraVeyAnJNRNwIEBFrc8uvAG5Js6uBYbnNh6YYPcTNzKwKatE7S8CVwEMRcVkuPji32snA0jQ9BxgvaXdJI4CRwH3AAmCkpBGSdiNrfJ9TjXMwM7NMLa5E/gE4FVgiaVGKfQmYIGkUEMBK4FMAEbFM0myyBvMtwDkRsRVA0rnAPKAfMDMillXvNMzMrBa9s34PqItFc3vYZiowtYv43J62s51bT0+0+2l2s/rgJ9bNzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0vx6XKtLfvWu2c7BVyJmZlaai4iZmZXmImJmZqW5iJiZWWluWLeG5BGCzarDVyJmZlaai4iZmZXm21lmnfhWmFlxvhIxM7PS6v5KRNJY4F/J3rP+04iYVuOUrIH5SXmz16rrIiKpH/BD4BhgFbBA0pyIeLC2mZl1zbfKrNHUdREBDgfaI2IFgKTrgXGAi4jVnd5c5Wxv2+3pzb5d/JqbIqLWOZQm6cPA2Ij4ZJo/FTgiIs7ttN5kYHKaPQB4JLd4H+AvVUi3Vnx+9a/Rz7HRzw8a4xzfFhEDOwfr/UqkkIiYAczoapmktohorXJKVePzq3+Nfo6Nfn7Q2OdY772zVgPDcvNDU8zMzKqg3ovIAmCkpBGSdgPGA3NqnJOZWdOo69tZEbFF0rnAPLIuvjMjYtkO7qbL21wNxOdX/xr9HBv9/KCBz7GuG9bNzKy26v12lpmZ1ZCLiJmZlda0RUTSWEmPSGqXNKXW+VSCpJWSlkhaJKmt1vn0lqSZktZJWpqLDZA0X9Ly9N2/ljn2VjfneImk1el3XCTphFrm2BuShkm6U9KDkpZJOj/FG+J37OH8GuY37Kwp20TScCl/JjdcCjCh0YZLkbQSaI2Ien/ICQBJRwHPAVdHxEEp9i1gQ0RMS/8z0D8iLqxlnr3RzTleAjwXEd+pZW59QdJgYHBE3C9pT2AhcBJwGg3wO/ZwfqfQIL9hZ816JfLKcCkR8TegY7gU24lFxN3Ahk7hccCsND2L7B9s3ermHBtGRKyJiPvT9CbgIWAIDfI79nB+DatZi8gQ4Inc/Coa84cO4HZJC9PQL41oUESsSdNPAoNqmUwFnStpcbrdVZe3ejqT1AIcDNxLA/6Onc4PGvA3hOYtIs1idEQcAhwPnJNulTSsyO7NNuL92cuB/YFRwBrguzXNpg9IehNwA/DZiNiYX9YIv2MX59dwv2GHZi0iTTFcSkSsTt/rgJvIbuM1mrXpPnTH/eh1Nc6nz0XE2ojYGhEvA1dQ57+jpF3J/sBeExE3pnDD/I5dnV+j/YZ5zVpEGn64FElvTA17SHojcCywtOet6tIcYFKangTcXMNcKqLjj2tyMnX8O0oScCXwUERcllvUEL9jd+fXSL9hZ03ZOwsgdbH7Pq8OlzK1thn1LUn7kV19QDa8zbX1fo6SrgPGkA2rvRa4GPgVMBsYDjwOnBIRddsw3c05jiG7DRLASuBTufaDuiJpNPA7YAnwcgp/iazdoO5/xx7ObwIN8ht21rRFxMzMeq9Zb2eZmVkfcBExM7PSXETMzKw0FxEzMyvNRcTMzEpzEbGGJum5CuxzVH4U1jRC6+d7sb+PSHpI0p19k2HpPFZK2qeWOVj9cREx23GjgL4cyvsM4MyI+EAf7tOsKlxErGlI+oKkBWkQvH9JsZZ0FXBFev/D7ZL2SMsOS+sukvRtSUvTCAeXAh9N8Y+m3R8o6S5JKySd183xJ6T3uyyV9M0U+yowGrhS0rc7rT9Y0t3pOEslvS/FL5fUlvL9l9z6KyV9I63fJukQSfMkPSrprLTOmLTPW5W9T+fHkrb5OyDp45LuS/v6iaR+6XNVymWJpP/Vy5/EGkFE+ONPw37I3uEA2bAvMwCR/c/TLcBRQAuwBRiV1psNfDxNLwX+Pk1PA5am6dOAH+SOcQnwR2B3sifNnwJ27ZTHvsD/AwaSjSDwf4CT0rK7yN770jn3C4Avp+l+wJ5pekAudhfwnjS/Evh0mv4esBjYMx1zbYqPAf4K7Je2nw98OLf9PsC7gP/sOAfgR8BE4FBgfi6/vWv9+/pT+4+vRKxZHJs+DwD3A+8ERqZlj0XEojS9EGiRtDfZH+0/pfi129n/rRGxObIXgK1j26HMDwPuioj1EbEFuIasiPVkAXB6einV30X2fgqAUyTdn87l3cCBuW06xoBbAtwbEZsiYj2wOZ0TwH2RvUtnK3Ad2ZVQ3tFkBWOBpEVpfj9gBbCfpH+TNBbYiDW919U6AbMqEfCNiPjJa4LZOx8250JbgT1K7L/zPnr9bysi7k7D958IXCXpMrJxmT4PHBYRT0u6Cnh9F3m83Cmnl3M5dR7rqPO8gFkRcVHnnCS9FzgOOIvsbX2f2NHzssbiKxFrFvOAT6T3PCBpiKS3drdyRDwDbJJ0RAqNzy3eRHabaEfcB7xf0j7KXs88AfhtTxtIehvZbagrgJ8ChwB7Ac8Dz0oaRPaumB11eBrBehfgo8DvOy2/A/hwx38fZe8/f1vqubVLRNwAfCXlY03OVyLWFCLidknvAv6UjdbNc8DHya4aunMGcIWkl8n+4D+b4ncCU9Ktnm8UPP4aZe8Ov5Ps//RvjYjtDXc+BviCpJdSvhMj4jFJDwAPk72d8w9Fjt/JAuAHwNtTPjflF0bEg5K+QvZWzF2Al4BzgBeBn+Ua4re5UrHm41F8zboh6U0R8VyangIMjojza5xWr0gaA3w+Ij5Y41SsQfhKxKx7J0q6iOzfyeNkvbLMLMdXImZmVpob1s3MrDQXETMzK81FxMzMSnMRMTOz0lxEzMystP8PpPFMfpeALD4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4b50c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ea6ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc24c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe113e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b024570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a183fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "079bf06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  220 36624 64018 ... 54000 14577 64229]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c283eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50332815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ac857d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dbc6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d07bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31963\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23716\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8247\n",
      "단어 집합에서 희귀 단어의 비율: 74.19829177486469\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.392680763650513\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "455cae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40251540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15, 9, 74, 853, 2, 122, 15, 39, 450, 119, 623, 108], [32, 44, 5257, 13, 7, 78, 208, 159, 1200, 77, 250, 100, 4280], [3, 2193, 90, 185, 3, 9, 10, 53, 117, 76, 1004, 430, 1205, 1324, 785, 199, 371]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8959d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65118cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10478\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8103\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2375\n",
      "단어 집합에서 희귀 단어의 비율: 77.33346058408092\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.867252444329586\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b30fdbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 73], [1], [1, 1668, 10, 29, 225], [1, 24, 16], [1, 3, 52, 16]]\n",
      "target\n",
      "decoder  [[73, 2], [2], [1668, 10, 29, 225, 2], [24, 16, 2], [3, 52, 16, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0a779b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1264\n",
      "삭제할 테스트 데이터의 개수 : 334\n",
      "훈련 데이터의 개수 : 51391\n",
      "훈련 레이블의 개수 : 51391\n",
      "테스트 데이터의 개수 : 12829\n",
      "테스트 레이블의 개수 : 12829\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72027771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 추가 (전처리 완료)\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5315f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24504f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a0df4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b3e05d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,145,360\n",
      "Trainable params: 4,145,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d1c0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 142s 662ms/step - loss: 2.6966 - val_loss: 2.4139\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 133s 662ms/step - loss: 2.3578 - val_loss: 2.2810\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 134s 667ms/step - loss: 2.2267 - val_loss: 2.1679\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 133s 664ms/step - loss: 2.1116 - val_loss: 2.0774\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 135s 671ms/step - loss: 2.0279 - val_loss: 2.0207\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 131s 653ms/step - loss: 1.9640 - val_loss: 1.9863\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 130s 649ms/step - loss: 1.9097 - val_loss: 1.9531\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 129s 643ms/step - loss: 1.8643 - val_loss: 1.9256\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 129s 640ms/step - loss: 1.8234 - val_loss: 1.9069\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 128s 638ms/step - loss: 1.7875 - val_loss: 1.8914\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 128s 637ms/step - loss: 1.7536 - val_loss: 1.8816\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 128s 639ms/step - loss: 1.7225 - val_loss: 1.8729\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 128s 638ms/step - loss: 1.6943 - val_loss: 1.8676\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 128s 639ms/step - loss: 1.6677 - val_loss: 1.8632\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 128s 637ms/step - loss: 1.6422 - val_loss: 1.8643\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 128s 636ms/step - loss: 1.6182 - val_loss: 1.8594\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 128s 636ms/step - loss: 1.5948 - val_loss: 1.8552\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 127s 634ms/step - loss: 1.5729 - val_loss: 1.8533\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 128s 638ms/step - loss: 1.5510 - val_loss: 1.8555\n",
      "Epoch 20/50\n",
      "201/201 [==============================] - 127s 634ms/step - loss: 1.5310 - val_loss: 1.8572\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ac7fc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fb593a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12e76d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52a918e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d7c89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eebc5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e36ba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : tried brands dried mango brand always one prefer local refer dried mango seasonal fruit available much time amazon always find favorite brand find price mangos arrive timely manner good shelf life \n",
      "실제 요약 : delicious dried \n",
      "예측 요약 :  love these\n",
      "\n",
      "\n",
      "원문 : pretty good opinion nearly good teriyaki beef steak nuggets bad either sort prime rip au jus flavoring tell meat prime rib definitely work try see like \n",
      "실제 요약 : pretty good \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : great coffee regular cup tried smallest cup espresso delicious give try \n",
      "실제 요약 : tully italian roast \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : pumps color matches perfectly work great problem go lock pump pump one shot syrup need plan ahead know much trouble used business party would great going go back regular cap spoon \n",
      "실제 요약 : and pump works perfectly but \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : time favorite tea nice hint cinnamon great time day easily go teabags day probably percent hot tea drink bigelow cinnamon stick tea tried cinnamon teas far best one yet thank bigelow thank amazon com carrying bulk \n",
      "실제 요약 : my favorite tea \n",
      "예측 요약 :  love this tea\n",
      "\n",
      "\n",
      "원문 : pepperoni beef sticks best ever taste begging wish sold locally simply great smoke taste mild give heartburn \n",
      "실제 요약 : beef sticks are great \n",
      "예측 요약 :  best beef jerky ever\n",
      "\n",
      "\n",
      "원문 : tasty chocolate sweet husband mentioned likes bittersweet chocolate taste dark chocolate seems sweeter brands \n",
      "실제 요약 : good chocolate \n",
      "예측 요약 :  dark chocolate\n",
      "\n",
      "\n",
      "원문 : use always reliable quality always use always reliable quality always \n",
      "실제 요약 : perfect \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : wife avid keurig coffee fans started ordering flavored pods soon learned likes back couple full strength go de caf last cup mahogany choice full blend smooth excellent taste aroma totally satisfied order \n",
      "실제 요약 : down to almost none \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : bought christmas gift shipping almost much product otherwise problem \n",
      "실제 요약 : shipping high \n",
      "예측 요약 :  great gift\n",
      "\n",
      "\n",
      "원문 : case arrived quickly good shape tastes great made pumpkin bread right away thought best tasting pumpkin bread \n",
      "실제 요약 : great tasting pumpkin \n",
      "예측 요약 :  best gluten free bread\n",
      "\n",
      "\n",
      "원문 : find better gluten free pancake mix matter fact much prefer gluten free pancakes regular pancakes love bisquick product \n",
      "실제 요약 : the best gf mix out there \n",
      "예측 요약 :  great gluten free pasta\n",
      "\n",
      "\n",
      "원문 : always enjoyed newman products including doggy treats chocolate could aging taste buds taste differently bad taste kinda bland exciting \n",
      "실제 요약 : kinda bland \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : think excellent great source protien perfect go snack mini bags inside hold six pieces grab one go \n",
      "실제 요약 : excellent \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : refreshing blend green white herbal teas low caffeine love idea white tea find incredibly bland mixing herbs rooibos jasmine green tea makes wonderful steep cup four times high quality incredibly tasty like plain sweetened honey \n",
      "실제 요약 : delightful \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : great price great ingredients great food stage chunky foods month old loved literally screaming laughing chicken stars highly recommend great organic food \n",
      "실제 요약 : our month old daughter loves this \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : im starting make wine dont really much knowledge whats good whats however happy yeast produced cant wait age bit get nice wine \n",
      "실제 요약 : good \n",
      "예측 요약 :  good product but\n",
      "\n",
      "\n",
      "원문 : read ingredients corn meal soybean meal corn gluten meal grains cause inflammation arthritis diabetes research dogs really eating look ingredients stella chewy products products love fur babies know ray loves hoping would given us better product late \n",
      "실제 요약 : corn and soy no no no \n",
      "예측 요약 :  my dog loves these\n",
      "\n",
      "\n",
      "원문 : wonderful see could get loved maxwell house coffee come house every two months less could buy store great deal great coffee thanks amazon \n",
      "실제 요약 : great deal great coffee \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : tried strawberry good taste would expected really good otherwise use supplement workouts \n",
      "실제 요약 : workout supplement \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : usually drink decaf health reasons found coffee robust flavor without bitter prefer coffee taste close coffee ice cream possible coffee came pretty close ideal added cream sugar friend drinks black also liked much stomach issues either us \n",
      "실제 요약 : good coffee \n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : dont much becuase makes poop day awesome detox sometimes makes good good \n",
      "실제 요약 : this works \n",
      "예측 요약 :  great\n",
      "\n",
      "\n",
      "원문 : little saltines best ever tasted larger version mile put soup use snack really great tasting http amazon com \n",
      "실제 요약 : great \n",
      "예측 요약 :  best pancake mix\n",
      "\n",
      "\n",
      "원문 : bob red mill always highest quality always choose brand said must say soy flour pretty darn nasty tasting suggest going use blend flours probably get used taste kinda leaves aftertaste unpleasant least good luck \n",
      "실제 요약 : the good and the bad \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : gatorade follow directions makes tasty drink powder form allow taste kind nice like mine sweet took traveled country used bottled water tasted great \n",
      "실제 요약 : this is \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : extremely pleased fast shipping product top quality try cant live without say \n",
      "실제 요약 : product service \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : son gluten free diet bars far best tasting found \n",
      "실제 요약 : crispy bars \n",
      "예측 요약 :  gluten free\n",
      "\n",
      "\n",
      "원문 : buying cat grass many years product well priced works good expensive packages cats grown healthy happy since grass great seller delivered time product sold exactly wanted purchase \n",
      "실제 요약 : cat grass does grow real cats \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : went rocket fizz sample brands ginger beer bought different ginger beers tasted one found brand wonderful smooth taste drink cannot without tell everyone wonderful product taste never drink brands great product \n",
      "실제 요약 : best have ever tasted \n",
      "예측 요약 :  ginger\n",
      "\n",
      "\n",
      "원문 : found anyone touch price product amazon quality best good size really lasts needs best taste great use especially night get munchies fix sugar free instant coffee put spoon full coconut oil cuts appetite keeps diet \n",
      "실제 요약 : great product \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : feeding dogs natural balance years love proven make healthier \n",
      "실제 요약 : best dog food around \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : bit skeptical bought product longer mixed bouillon quinoa definitely buy great taste gluten free well thanks sons great product \n",
      "실제 요약 : this one \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : new vegan searched online different types bars healthy without giving taste love taste bars today key lime pie fabulous cannot wait try flavors \n",
      "실제 요약 : favorite bars \n",
      "예측 요약 :  love these\n",
      "\n",
      "\n",
      "원문 : use bread machine nothing could easier sometimes add little honey extra salt poppy seeds nuts variation makes full bodied bread keep well freeze well thank goodness pamela \n",
      "실제 요약 : great bread and gluten free \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : drink refreshing little sweet found others household enjoyed might fair give four star \n",
      "실제 요약 : sweet \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : georgia fox terrier learned work tug jug first day got fill dry dog food treats likes better food dish daughter law chihuahua boxer bought another toy chihuahua takes toy cage let boxer near ordered another one son two \n",
      "실제 요약 : and love tug jug \n",
      "예측 요약 :  dog likes it\n",
      "\n",
      "\n",
      "원문 : love tea drink daily great tea great taste stomach aids digestion \n",
      "실제 요약 : licorice mint tea \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : picked grocery shopping love give slight weird aftertaste even enough stop snacking excited try flavors \n",
      "실제 요약 : great snack \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : wish amazon would get classic pate varieties fancy feast cats eat types love pate classic varieties please get flavors amazon buy \n",
      "실제 요약 : my cats love the classic \n",
      "예측 요약 :  my cats love these\n",
      "\n",
      "\n",
      "원문 : tried many green teas far best taste refreshing overpowering makes want curl relax \n",
      "실제 요약 : green tea soothing relaxing great tasting \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : like combine basmati wild rice jasmine thai glad amazon carrying rice see jasmine thai anyway used buy years ago came box reason believe took market came back new packaging buying years time around grocery store able buy going business thanks amazon buy line \n",
      "실제 요약 : hands down best rice ever \n",
      "예측 요약 :  wonderful rice\n",
      "\n",
      "\n",
      "원문 : taste great bearable could get used smell box still sitting drawer plans stock future \n",
      "실제 요약 : tea \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  not as good as the\n",
      "\n",
      "\n",
      "원문 : toy excellent golden retriever teething perfect stars product description accurate picture showed rex received big deal multiple description indicate one getting \n",
      "실제 요약 : excellent product but buyer beware \n",
      "예측 요약 :  not for\n",
      "\n",
      "\n",
      "원문 : chocolates absolutely best smooth taste almost delicate texture absolute must chocolate fan never fan milk chocolate chocolates absolute exception highly recommend chocolates anyone loves chocolate much \n",
      "실제 요약 : chocolate delightful treat \n",
      "예측 요약 :  best chocolate ever\n",
      "\n",
      "\n",
      "원문 : chips regular house fact chips buy bbq flavor favorite buy single serving packs buy bigger bag hard stop eating \n",
      "실제 요약 : best chips ever \n",
      "예측 요약 :  great chips\n",
      "\n",
      "\n",
      "원문 : cherry jolly ranchers definitely best flavor package way get cherry arrived fresh tasty exactly hoped stix different suppliers bit taste sort melted within wrapper \n",
      "실제 요약 : only way to get all cherry \n",
      "예측 요약 :  love these\n",
      "\n",
      "\n",
      "원문 : got ekobrew today tried fan since came ekobrew design seems beat first flat bottom makes easy fill usually run two larger cup coffee ekobrew lid stays shut leak water top surprised easily grounds came quick rinse ready go seems best choice around avoiding high cost cups \n",
      "실제 요약 : great design \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : great product fans soda almost smells like dr pepper great taste great dr pepper bbq enthusiasts \n",
      "실제 요약 : great dr pepper product \n",
      "예측 요약 :  good stuff\n",
      "\n",
      "\n",
      "원문 : purchased pack boxes ounce vita coco coconut water package arrived fine put boxes refrigerator boy make mess started leaking overnight wife happy leaking packs soda bottles want try putting remaining packs refrigerator transfer soda bottles well wish could get refund way return easy way contact vendor turned real pain \n",
      "실제 요약 : beware messy \n",
      "예측 요약 :  not\n",
      "\n",
      "\n",
      "원문 : awesome stuff host war room work go thru cases sweet cheesy cannot ask anything better \n",
      "실제 요약 : this stuff is like crack \n",
      "예측 요약 :  love this stuff\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28cbc9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4eb4147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5cff393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a654e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d71c2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b893bc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12be2c7",
   "metadata": {},
   "source": [
    "## 여기부터 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423ea96",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79452dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23c79d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49092</th>\n",
       "      <td>Saddam Hussein's daughter on Iraq's most wante...</td>\n",
       "      <td>Former Iraqi dictator Saddam Hussein's eldest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81044</th>\n",
       "      <td>Reliance stock hits 9 year high as Jio announc...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries stock on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93253</th>\n",
       "      <td>People in Mumbai clean 20,000 kg of trash</td>\n",
       "      <td>Nearly 100 residents of Kandivali in Mumbai ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20941</th>\n",
       "      <td>UAE deports Indian over suspected links with ISIS</td>\n",
       "      <td>The UAE has deported a 36-year-old engineer fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80521</th>\n",
       "      <td>India's Premier Futsal to be bigger this year:...</td>\n",
       "      <td>Former World Cup-winning Brazilian footballer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>Public sector banks' losses rise 3.5 times hig...</td>\n",
       "      <td>Due to mounting bad loans, state-owned banks s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94954</th>\n",
       "      <td>100 cities organise pillow fights to help home...</td>\n",
       "      <td>Over 100 cities around the world recently host...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14502</th>\n",
       "      <td>Turkey Prez tells ministers to stop using US f...</td>\n",
       "      <td>Turkish President Recep Tayyip ErdoÃÂan on S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17815</th>\n",
       "      <td>Nadal would be great as Real Madrid President:...</td>\n",
       "      <td>Real Madrid's current President Florentino Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37757</th>\n",
       "      <td>Kane scores in injury time to help England sta...</td>\n",
       "      <td>Captain Harry Kane scored twice, including an ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "49092  Saddam Hussein's daughter on Iraq's most wante...   \n",
       "81044  Reliance stock hits 9 year high as Jio announc...   \n",
       "93253         People in Mumbai clean 20,000 kg of trash    \n",
       "20941  UAE deports Indian over suspected links with ISIS   \n",
       "80521  India's Premier Futsal to be bigger this year:...   \n",
       "9561   Public sector banks' losses rise 3.5 times hig...   \n",
       "94954  100 cities organise pillow fights to help home...   \n",
       "14502  Turkey Prez tells ministers to stop using US f...   \n",
       "17815  Nadal would be great as Real Madrid President:...   \n",
       "37757  Kane scores in injury time to help England sta...   \n",
       "\n",
       "                                                    text  \n",
       "49092  Former Iraqi dictator Saddam Hussein's eldest ...  \n",
       "81044  Mukesh Ambani-led Reliance Industries stock on...  \n",
       "93253  Nearly 100 residents of Kandivali in Mumbai ca...  \n",
       "20941  The UAE has deported a 36-year-old engineer fr...  \n",
       "80521  Former World Cup-winning Brazilian footballer ...  \n",
       "9561   Due to mounting bad loans, state-owned banks s...  \n",
       "94954  Over 100 cities around the world recently host...  \n",
       "14502  Turkish President Recep Tayyip ErdoÃÂan on S...  \n",
       "17815  Real Madrid's current President Florentino Per...  \n",
       "37757  Captain Harry Kane scored twice, including an ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01889c92",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "### 2-1) 데이터 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3442befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "886c5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98262\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "data.drop_duplicates(subset = ['headlines'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "385631cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum()) # 결측값 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70ede635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b2a9257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28139474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "\n",
    "# 요약할 때 뭘 추가 삭제해야할지는 영어 사용자가 아니면 생각하기 어렵기때문에, 일단 패스 마지막까지 결과를 보고 고민해보자\n",
    "# 대충 자주사용하는 단축어나 구어체, 자주 나오는 오타, 신조어 등등 있을꺼같은데... 영어는 잘 모르겠음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7b33aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ae97510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "clean_headlines = []\n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f09234c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73f4b871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8769c",
   "metadata": {},
   "source": [
    "### 2-2) 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "731461d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.10029309397326\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299444342675704\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9010c5a5",
   "metadata": {},
   "source": [
    "### 분포를 확인해보니 따로 최대길이를 지정해서 삭제할 필요는 없어보인다.\n",
    "### 1글자짜리 저 데이터가 좀 거슬리긴하는데 패딩처리하면 큰 문제는 없을 듯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef050c7",
   "metadata": {},
   "source": [
    "### 2-3) 시작 토큰과 종료 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "45f38ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58695d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2e302",
   "metadata": {},
   "source": [
    "### 2-4) 훈련 데이터와 테스트 데이터의 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "357be996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79619 60634  9383 ... 85031 16087 71359]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87322246",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ab67156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19652\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40b4752a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78610\n",
      "훈련 레이블의 개수 : 78610\n",
      "테스트 데이터의 개수 : 19652\n",
      "테스트 레이블의 개수 : 19652\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f58f6",
   "metadata": {},
   "source": [
    "### 2-5) 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55ce7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50649beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69520\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47366\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22154\n",
      "단어 집합에서 희귀 단어의 비율: 68.13291139240506\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.4865288590681858\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "712a2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec9076fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160, 20, 60, 1590, 313, 1962, 6259, 21, 116, 454, 9622, 3916, 1962, 746, 14835, 24, 4725, 20, 4, 2496, 379, 142, 1361, 1, 10704, 407, 10705, 313, 1962], [3, 13, 64, 43, 28, 5, 16, 2550, 14299, 6708, 5499, 7158, 711, 2018, 253, 478, 365, 2463, 347, 636, 5500, 1157, 5, 16, 612, 129, 484, 250, 1304, 1445, 5, 86], [1792, 119, 988, 569, 59, 1, 4094, 279, 101, 310, 12565, 1500, 18351, 569, 1495, 3583, 1150, 65, 18351, 1500, 12962, 65, 1105, 1225, 12565, 1343, 6475, 17482, 16004, 3126, 1938, 1792, 4013, 4013, 1225, 7067]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "162b15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02fabc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 30044\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 19598\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10446\n",
      "단어 집합에서 희귀 단어의 비율: 65.23099454133937\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.623818352728428\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d150db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 583, 3, 2064, 10, 9535, 84, 21, 64], [1, 40, 880, 9536, 5906, 6, 5007, 285, 108, 32, 13, 181], [1, 691, 279, 5202, 1152, 1146, 16], [1, 144, 3, 445, 1091, 2125, 1560, 916, 13, 15, 3171, 1979], [1, 3172, 228, 2262, 3036, 1262, 5, 383, 1426]]\n",
      "target\n",
      "decoder  [[583, 3, 2064, 10, 9535, 84, 21, 64, 2], [40, 880, 9536, 5906, 6, 5007, 285, 108, 32, 13, 181, 2], [691, 279, 5202, 1152, 1146, 16, 2], [144, 3, 445, 1091, 2125, 1560, 916, 13, 15, 3171, 1979, 2], [3172, 228, 2262, 3036, 1262, 5, 383, 1426, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 10000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "69dfbe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 78610\n",
      "훈련 레이블의 개수 : 78610\n",
      "테스트 데이터의 개수 : 19652\n",
      "테스트 레이블의 개수 : 19652\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da4381",
   "metadata": {},
   "source": [
    "### 2-6) 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5df895d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#왜또 post로 패딩하는지 모르겠지만 post를 뺄예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec54233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len)\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len)\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len)\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len)\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len)\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c488d3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  160,    20,    60,  1590,   313,  1962,  6259,    21,   116,\n",
       "          454,  9622,  3916,  1962,   746, 14835,    24,  4725,    20,\n",
       "            4,  2496,   379,   142,  1361,     1, 10704,   407, 10705,\n",
       "          313,  1962,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4489c54",
   "metadata": {},
   "source": [
    "## 3. 어텐션 메커니즘 사용\n",
    "### 3-1) 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ee2a11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5dca3e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "089bf3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 128)      2560000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 50, 256), (N 394240      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 50, 256), (N 525312      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 128)    1280000     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 50, 256), (N 525312      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  394240      embedding_3[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 10000)  2570000     lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,249,104\n",
      "Trainable params: 8,249,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86d61bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 128)      2560000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 50, 256), (N 394240      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 50, 256), (N 525312      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 128)    1280000     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 50, 256), (N 525312      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  394240      embedding_3[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_7[0][0]                     \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_7[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 10000)  5130000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,809,360\n",
      "Trainable params: 10,809,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ac545",
   "metadata": {},
   "source": [
    "### 3-2) 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65df2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 207s 649ms/step - loss: 6.5778 - val_loss: 6.3193\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 199s 645ms/step - loss: 6.0249 - val_loss: 5.7991\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 203s 658ms/step - loss: 5.6183 - val_loss: 5.5058\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 202s 655ms/step - loss: 5.3236 - val_loss: 5.3045\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 201s 654ms/step - loss: 5.0895 - val_loss: 5.1330\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 201s 654ms/step - loss: 4.8912 - val_loss: 4.9818\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 202s 655ms/step - loss: 4.7152 - val_loss: 4.8802\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 202s 656ms/step - loss: 4.5584 - val_loss: 4.7871\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 201s 652ms/step - loss: 4.4202 - val_loss: 4.7147\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 201s 652ms/step - loss: 4.3047 - val_loss: 4.6571\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 201s 654ms/step - loss: 4.2008 - val_loss: 4.6212\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 201s 652ms/step - loss: 4.1054 - val_loss: 4.5630\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 201s 651ms/step - loss: 4.0157 - val_loss: 4.5340\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 201s 652ms/step - loss: 3.9358 - val_loss: 4.5032\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 200s 650ms/step - loss: 3.8591 - val_loss: 4.4888\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 200s 648ms/step - loss: 3.7911 - val_loss: 4.4661\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 200s 649ms/step - loss: 3.7252 - val_loss: 4.4447\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 200s 648ms/step - loss: 3.6646 - val_loss: 4.4332\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 199s 648ms/step - loss: 3.6042 - val_loss: 4.4154\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 200s 649ms/step - loss: 3.5514 - val_loss: 4.4188\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 200s 650ms/step - loss: 3.4973 - val_loss: 4.4187\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8857138a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5acd8ce",
   "metadata": {},
   "source": [
    "### 3-3 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4cb6a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f750b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a74d067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f8da57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe86b64",
   "metadata": {},
   "source": [
    "### 3-4) 모델 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "02fa6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2headlines(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07492eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : apple fixed ios vulnerability year old exploited october last year trick iphones us emergency service number teenager shared link twitter tapping non stop till iphone shut however tapping link android devices redirected users site said \n",
      "실제 요약 : fixes ios that made iphones dial non stop \n",
      "예측 요약 :  apple admits iphone iphone report\n",
      "\n",
      "\n",
      "원문 : inflation based wholesale price index eased december previous month due lower food inflation per government data inflation food articles slowed fuel inflation rose december however retail inflation december accelerated month high \n",
      "실제 요약 : wholesale inflation eases to in december \n",
      "예측 요약 :  inflation falls to month low of\n",
      "\n",
      "\n",
      "원문 : world largest cryptocurrency bitcoin plunged much last week record around however bitcoin cash rival split original bitcoin august offering increased transaction speeds jumped nearly since friday comes developers called upgrade proposal would caused another split bitcoin \n",
      "실제 요약 : bitcoin plunges from record high of \n",
      "예측 요약 :  bitcoin bitcoin bitcoin surges to record\n",
      "\n",
      "\n",
      "원문 : four jawans martyred one injured sunday firing pakistan along line control jammu kashmir rajouri continuous ceasefire violations pakistan forced hundreds people near border evacuate villages schools near border ordered shut around week due continuous shelling \n",
      "실제 요약 : jawans martyred in pakistan firing along loc in \n",
      "예측 요약 :  jawans martyred in ceasefire violation in pakistan\n",
      "\n",
      "\n",
      "원문 : bank baroda tuesday posted year year rise profit crore quarter ended december net interest income rose crore compared crore period year ago lender asset quality eased gross bad loans declining year ago period \n",
      "실제 요약 : bank of baroda profit surges to crore \n",
      "예측 요약 :  kotak mahindra profit falls to crore\n",
      "\n",
      "\n",
      "원문 : miss usa sarah rose apologised mocking fellow miss universe contestants miss vietnam miss cambodia speaking english said something realise perceived respectful would never intend hurt another said miss universe opportunity women learn cultures added \n",
      "실제 요약 : usa apologises for mocking non english speaking contestants \n",
      "예측 요약 :  miss miss world manushi chhillar miss universe\n",
      "\n",
      "\n",
      "원문 : per reports nude pictures actress dakota johnson lead actress fifty shades grey film series leaked online hackers accessed private pictures earlier nude private pictures celebrities including kristen stewart tiger woods miley cyrus danielle lloyd pregnant reportedly leaked online \n",
      "실제 요약 : of grey actress nude pic leaked online report \n",
      "예측 요약 :  priyanka chopra shares picture with her report\n",
      "\n",
      "\n",
      "원문 : french security expert goes alias elliot posted video showing bypass aadhaar android app password protection one minute referring latest version said attacker needs physical access phone aadhaar think project size deserves maximum security tweeted \n",
      "실제 요약 : security expert hacks aadhaar app in one minute \n",
      "예측 요약 :  facebook suspends whatsapp account over copyright\n",
      "\n",
      "\n",
      "원문 : congress leader shashi tharoor monday tweeted poem media accepted friend challenge find word word refers encouraging excessive interest sexual matters especially sexual activity others last year tharoor tweet farrago went viral social media \n",
      "실제 요약 : tharoor accepts friend challenge finds for \n",
      "예측 요약 :  tharoor apologises for tharoor tweet on twitter\n",
      "\n",
      "\n",
      "원문 : singer justin bieber monday appeared accidentally tweet phone number quickly deleting deleted tweets read change hit whatsapp reacting twitter user commented justin bieber accidentally tweeted phone number added group chat \n",
      "실제 요약 : whatsapp too bieber shares number deletes tweets later \n",
      "예측 요약 :  twitter reacts to user tweets user on\n",
      "\n",
      "\n",
      "원문 : ailing goa cm manohar parrikar tuesday attended office first time four months held meeting cabinet colleagues former defence minister seen tube nose climbed stairs aides help year old suffering pancreatic ailment remained confined residence \n",
      "실제 요약 : attends office for first time in four months \n",
      "예측 요약 :  cm parrikar inaugurates first ever meeting\n",
      "\n",
      "\n",
      "원문 : indian chef anand whose bangkok based indian restaurant rated asia best restaurant three consecutive years returning india four city tour visit mumbai delhi bengaluru chennai create menu taj hotels notably chef recently announced would close award winning restaurant \n",
      "실제 요약 : rated chef anand returns to india for tour \n",
      "예측 요약 :  indian city named best in india\n",
      "\n",
      "\n",
      "원문 : virat kohli friday shared picture sitting chair sat international debut odi sri lanka august started chair date ground years today indian cricket team grateful kohli captioned picture \n",
      "실제 요약 : this very chair yrs ago kohli on anniversary \n",
      "예측 요약 :  rohit sharma meets kohli on his birthday\n",
      "\n",
      "\n",
      "원문 : prime minister narendra modi tuesday met fishermen affected cyclone ockhi tamil nadu kanyakumari also visited coastal villages cyclone lakshadweep kerala thiruvananthapuram damaged properties hundreds fishermen reported died several others missing ockhi struck southern coast november \n",
      "실제 요약 : pm modi meets fishermen affected by cyclone ockhi \n",
      "예측 요약 :  cyclone ockhi is lives in flood hit\n",
      "\n",
      "\n",
      "원문 : year old boy blew office russia federal security service country main domestic security intelligence service wednesday bomber reportedly described communist wrote social media would target cases people three employees injured blast \n",
      "실제 요약 : blows himself up at russia intelligence agency office \n",
      "예측 요약 :  us police arrest for cyber attack\n",
      "\n",
      "\n",
      "원문 : kannada actor investigated filed false robbery case group men actor vikram karthik alleged men stole wallet phone car however police said actor vehicle collided car following handed wallet mobile phone car owner promising reimburse \n",
      "실제 요약 : kannada actor files false robbery case \n",
      "예측 요약 :  actress files complaint against actress\n",
      "\n",
      "\n",
      "원문 : according reuters report tesla executive ousted last month clash automaker ceo elon musk disagreement reportedly strategy firm tesla acquired november last year commenting ouster said definitely depart lost interest working \n",
      "실제 요약 : executive ousted after clash with elon musk report \n",
      "예측 요약 :  tesla ceo tesla ceo\n",
      "\n",
      "\n",
      "원문 : railway board chairman ashwani lohani recently asked senior staff address junior employees aap instead tum tu attempt boost self junior staff behaviour definitely need one dealings please provide leadership front lohani said \n",
      "실제 요약 : junior railway employees as aap not tu lohani \n",
      "예측 요약 :  chairman chairman appointed chairman of london\n",
      "\n",
      "\n",
      "원문 : former un secretary general receive state burial home country ghana september president nana said given burial status global icon diplomat statesman added nobel peace laureate passed away switzerland earlier month age \n",
      "실제 요약 : to get state burial in home country ghana \n",
      "예측 요약 :  prez kovind appointed as president of\n",
      "\n",
      "\n",
      "원문 : north korea goal establish real force us make us dare talk military option dprk north korean leader kim jong un reportedly said need run full speed consolidate military attack capacity nuclear us cannot cope jong un added nnn \n",
      "실제 요약 : us dare not talk on military options korea \n",
      "예측 요약 :  us kim jong un\n",
      "\n",
      "\n",
      "원문 : us based researchers led chemistry nobel laureate aziz developed high resolution technique mapping sites human genome undergoing repair following damage found cigarette smoke scientists aim understand quantity gene repair capacity smoking related mutations lead lung cancer specifically \n",
      "실제 요약 : by smoking at high resolution for st time \n",
      "예측 요약 :  scientists develop gene editing to\n",
      "\n",
      "\n",
      "원문 : asked university california whether ready prime ministerial candidate congress vice president rahul gandhi said absolutely ready ut way party works organisational election process decides process currently ongoing added \n",
      "실제 요약 : ready to be prime candidate rahul gandhi \n",
      "예측 요약 :  rahul gandhi is not\n",
      "\n",
      "\n",
      "원문 : per reports deepika padukone song ghoomar padmaavat covered using report added censor board examining committee asked producers remove shots stomach visible editing would disturbed flow submitted censor board suggested modifications \n",
      "실제 요약 : deepika in to be covered using report \n",
      "예측 요약 :  deepika padukone bans padmaavat in padmaavat\n",
      "\n",
      "\n",
      "원문 : photo sharing app instagram confirmed testing feature allows users users public posts story feature tested small percentage users also reportedly allows users rotate post users also others sharing posts story settings \n",
      "실제 요약 : instagram tests feature to others posts as story \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  instagram tests feature to feature in\n",
      "\n",
      "\n",
      "원문 : kkr took facebook share video year old batsman shubman gill belongs punjab learning bengali gill heard speaking several bengali lines like amar naam shubman kota among others gill player world cup bought kkr crore \n",
      "실제 요약 : kkr punjabi batsman shubman gill learns bengali language \n",
      "예측 요약 :  abhishek bachchan shares picture with rahane\n",
      "\n",
      "\n",
      "원문 : schools colleges ghaziabad uttar pradesh remain closed tomorrow preventive measure view ongoing farmers agitation tuesday protesters broke blocked nh delhi border following delhi police used water cannons tear gas disperse farmers protesting demands including farm loan waiver farmer friendly crop insurance \n",
      "실제 요약 : schools to remain shut tomorrow over farmers protest \n",
      "예측 요약 :  maharashtra govt approves darjeeling schools\n",
      "\n",
      "\n",
      "원문 : amazon said may share users payment data indian government regulators according commerce platform privacy policy keeping regulatory requirements license granted rbi amazon pay company spokesperson said comes time india drafting privacy bill \n",
      "실제 요약 : may share users payment data with indian government \n",
      "예측 요약 :  india data data india india\n",
      "\n",
      "\n",
      "원문 : bengaluru based car rental startup zoomcar said temporarily discontinue cycle sharing service december problem bookings getting consumers problem hardware availability vehicles quality zoomcar ceo greg reportedly said launched resumed next year revealed \n",
      "실제 요약 : zoomcar temporarily its cycle sharing service \n",
      "예측 요약 :  gurugram based on bike delivery startup\n",
      "\n",
      "\n",
      "원문 : alibaba digital marketing arm unveiled artificial intelligence powered tool produce lines copy second uses deep learning natural language processing technologies learn millions existing samples generate copy products company also claimed ai capable generating promotional functional content users \n",
      "실제 요약 : ai can produce lines of copy in second \n",
      "예측 요약 :  google launches smart speaker that can\n",
      "\n",
      "\n",
      "원문 : new zealand government wednesday announced plans tighten access skilled work visas help get jobs ahead migrants new measures aim solve problems housing shortages road congestion overcrowding new zealand due record high levels migration comes day australia abolished skilled visa programme \n",
      "실제 요약 : new zealand restricts worker visas \n",
      "예측 요약 :  new zealand new zealand\n",
      "\n",
      "\n",
      "원문 : month old baby fell window fourth floor apartment mumbai saved tree helped minimise impact fall child fell tree outside window slipping ground sustained injuries lips one leg taken hospital \n",
      "실제 요약 : before falling to ground from th floor survives \n",
      "예측 요약 :  baby dies after falling off mumbai\n",
      "\n",
      "\n",
      "원문 : mumbai based multi cryptocurrency exchange raised undisclosed amount pre series funding amount raised us based investment firm capital singapore based company beenext founded iit alumni rahul raj rakesh yadav along bits pilani alumnus aditya nayak facilitates trading cryptocurrencies like bitcoin ethereum \n",
      "실제 요약 : indian cryptocurrency exchange raises pre series \n",
      "예측 요약 :  startup raises crore from alibaba\n",
      "\n",
      "\n",
      "원문 : speaking inauguration programme uttar pradesh union minister nitin gadkari promised clean river ganga december year earlier august gadkari said projects namami gange programme worth crore nearing completion added projects undertaken private sector organisations \n",
      "실제 요약 : to clean of river ganga before dec gadkari \n",
      "예측 요약 :  gurugram cm inaugurates projects in bengaluru\n",
      "\n",
      "\n",
      "원문 : following death people fire delhi prime minister narendra modi said deeply fire factory bawana adding thoughts families lost lives said may injured recover quickly meanwhile delhi government ordered inquiry incident \n",
      "실제 요약 : by the fire at factory in pm modi \n",
      "예측 요약 :  pm modi arrested for kabul suicide\n",
      "\n",
      "\n",
      "원문 : taking dig karni sena padmaavat release user wrote karni sena villain marketing head padmaavat tweet read loved climax padmaavat everyone worried karni sena waiting outside multiplex another user wrote movie rajputs history karni sena ashamed seeing \n",
      "실제 요약 : sena villain marketing head of padmaavat tweets user \n",
      "예측 요약 :  bhansali padmavati calls deepika padmaavat\n",
      "\n",
      "\n",
      "원문 : archbishop paris hoping raise million repair th century cathedral major restoration work cathedral last carried notably million people visit landmark located island river annually \n",
      "실제 요약 : nearly crore needed for restoration work at \n",
      "예측 요약 :  million to be auctioned for million\n",
      "\n",
      "\n",
      "원문 : ludhiana court issued arrest warrant actor rakhi sawant allegedly making objectionable remarks sage valmiki wrote ramayana complaint filed allegedly hurting religious sentiments valmiki community comments made tv programme last year ludhiana police personnel left mumbai arrest warrant \n",
      "실제 요약 : arrest warrant against rakhi for her remarks on \n",
      "예측 요약 :  fir against journalist for calling journalist\n",
      "\n",
      "\n",
      "원문 : actress sridevi seen crying video message pakistani co stars adnan siddiqui ali played premiere film mom karachi really miss cannot even think film without two said sridevi adnan come india promote film \n",
      "실제 요약 : message to her pak co stars in mom \n",
      "예측 요약 :  ranveer singh shares video of sridevi\n",
      "\n",
      "\n",
      "원문 : facebook data scandal linked firm cambridge analytica planning raise million issuing cryptocurrency reports said prior facebook controversy exploring multiple options people monetise personal data including blockchain technology analytica said approached firm advises companies initial coin offering \n",
      "실제 요약 : scandal firm planned to launch own cryptocurrency report \n",
      "예측 요약 :  facebook data scandal firm sues facebook data\n",
      "\n",
      "\n",
      "원문 : australian cricketer david warner dropped brand ambassador south korean electronics company lg aftermath ball tampering scandal warner become brand ambassador company current deal renewed final weeks earlier today warner handed one year ban cricket australia \n",
      "실제 요약 : david warner loses sponsor over ball tampering controversy \n",
      "예측 요약 :  former bcci captain to offer into\n",
      "\n",
      "\n",
      "원문 : uttar pradesh government decided rename dental clinic jail ghaziabad aarushi talwar murdered age residence aarushi talwar parents rajesh nupur talwar also spent four years jail since accused murder case \n",
      "실제 요약 : to rename its dental clinic after aarushi talwar \n",
      "예측 요약 :  rajasthan jails dera dera provide penalty for\n",
      "\n",
      "\n",
      "원문 : bihar cm nitish kumar released state startup policy bihar entrepreneurship summit tuesday given youth entrepreneurs revised startup policy set crore fund encourage facilitate entrepreneurship chief minister said kumar also asked committee funding applications ensure transparency \n",
      "실제 요약 : bihar cm unveils startup policy announces crore fund \n",
      "예측 요약 :  bihar cm launches new scheme for startups\n",
      "\n",
      "\n",
      "원문 : centre made mandatory link aadhaar cards mobile connections new old february aadhaar mandatory getting new sim cards service providers directed existing customers using aadhaar numbers biometric details comes supreme court directive verify mobile numbers \n",
      "실제 요약 : makes aadhaar card mandatory for all mobile numbers \n",
      "예측 요약 :  aadhaar mandatory for aadhaar linking aadhaar\n",
      "\n",
      "\n",
      "원문 : format letters taken wherein ordered keyboard avoided stop keys together invention keyboard attributed american inventor christopher reportedly aimed slow arranging common letters hard reach spots \n",
      "실제 요약 : why are letters on in format \n",
      "예측 요약 :  startup makes its own app\n",
      "\n",
      "\n",
      "원문 : pakistan prime minister shahid khaqan abbasi warned us vision involving india afghanistan would detrimental peaceful solution owned led added comes response donald trump government south asia policy enhanced role india bring peace stability war torn country \n",
      "실제 요약 : india role in afghanistan would be pak pm \n",
      "예측 요약 :  pakistan pm may not indo pakistan pm\n",
      "\n",
      "\n",
      "원문 : congress spokesperson randeep surjewala said bjp led government new slogan seems aur aur pack le jane slamming government crore diamonds fraud case surjewala said group promoter jatin mehta fled india settled caribbean india extradition treaty caribbean pointed \n",
      "실제 요약 : bjp new slogan is pack le cong \n",
      "예측 요약 :  congress leader ke sarkar congress congress leader\n",
      "\n",
      "\n",
      "원문 : eyewitness kansas shooting incident indian student sharath killed restaurant said others took cover ran shot back witness said suspect wearing brown shirt demanded money pulled gun cctv footage suspect released police \n",
      "실제 요약 : cover but ran and was shot in back \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  shooting injured in shooting at us\n",
      "\n",
      "\n",
      "원문 : legacy years brings india range ultra hd smart full hd hd ready led tvs japanese tv giant offering minimum range led tvs icici avail extra discount sale amazon ends may apply \n",
      "실제 요약 : minimum of off on led tvs on amazon \n",
      "예측 요약 :  cabinet approves new minister\n",
      "\n",
      "\n",
      "원문 : world number petra kvitova become first female tennis player win madrid open thrice defeating world number kiki saturday kvitova forced action five months stabbed burglar home december year old four titles year \n",
      "실제 요약 : stabbed by burglar wins rd madrid open title \n",
      "예측 요약 :  tennis player wins world first female\n",
      "\n",
      "\n",
      "원문 : members bajrang dal rampur announced cash reward lakh beheading samajwadi party leader azam khan comes khan accused indian army saying women took away private parts soldiers bajrang dal also announced reward crore anyone paints face black feeds pork \n",
      "실제 요약 : dal declares lakh reward for beheading azam khan \n",
      "예측 요약 :  salman khan starrer tubelight attend tubelight\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2headlines(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe861d",
   "metadata": {},
   "source": [
    "## Step 4 실제 결과와 요약문 비교하기\n",
    "\n",
    "요약은 형편없다. 헤드라인은 단순 요약과는 달리 편집자의 주관에 따라 편향이나 과장이 포함된다는 점을 감안해서\n",
    "유사성이 떨어질꺼란 예상은 했는데 본문에 대한 적절한 요약도 하지 못하는 점을 알 수 있었다.\n",
    "비트코인이 사상 최하로 급락한 기사같은 경우  bitcoin bitcoin bitcoin surges to record 이라는 대충 보기에도 문법이 적절치 않은 요약도 있고\n",
    "방콕에 있는 인도 최고 레스토랑이 문을 닫았다는 기사에 인도 최고의 도시 indian city 라는 말을 하거나\n",
    "북한이 군사 능력을 증강해야한다고 했다는 기사에서는 us kim jong un (우리는 김정은) ~~뭐야 이거 무서워~~ 같은 요약을 하기도 했다.\n",
    "\n",
    "어쨌든 영어사용자가 아니라 뉘앙스나 표현, (생략된)문법 등이 익숙하지 않은 점도 분석을 어렵게 하는 요인이긴 하지만,\n",
    "적절한 요약을 성공한 사례가 드물고 아주 평이한 내용에서나 가끔 요약문과 유사한 내용을 내곤 했다.\n",
    "이전 자연어 처리에서 너무 단순한 단어만 반복해서 말하는 앵무새가 된 것을 보고\n",
    "단어사전이 좀 크면 좀 다채로운 표현을 사용하지 않을까 기대했는데 그렇지는 않은 거 같다.\n",
    "\n",
    "\n",
    "어쨌든 단어와 단어사이의 연관성을 가지고 요약을 한다는 측면에서\n",
    "이전의 영화 리뷰라던가 가사, 줄거리 등을 요약하는 것과는 달리\n",
    "뉴스 기사에는 인간의 다양한 삶의 측면이 모두 반영되므로, 빈도수가 낮은 단어들을 삭제하는 것이 적절한가 하는 고민이 들었다.\n",
    "예를 들면 '인플레이션' 이라는 단어가 자주 사용되진 않지만, 인플레이션 증가 / 인플레이션 감소 이 두단어만으로 \n",
    "아니 인플레이션 딱 한단어만 사용해도 뉴스 내용을 어느정도는 요약가능한데 이런 단어들을 사전에서 삭제해서\n",
    "오히려 중요한 단어는 빼고 변죽을 울리는 다른 내용들만 요약한게 아닐까 그런 생각이 든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e806c6",
   "metadata": {},
   "source": [
    "## Step 5. Summa을 이용해서 추출적 요약해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c951656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03d5bf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8511e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text= data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7b10186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    saurav kant alumnus upgrad iiit pg program mac...\n",
       "1    kunal shah credit card bill payment platform c...\n",
       "2    new zealand defeated india wickets fourth odi ...\n",
       "3    aegon life iterm insurance plan customers enjo...\n",
       "4    speaking sexual harassment allegations rajkuma...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "15f3d9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "85e1c1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "23eefcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(summarize(new_text[0], words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "28f53784",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = new_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "344e8891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(summarize(a, words=5))\n",
    "# 왜 안되지??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0d00e09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(summarize(new_text[1], words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ef2fc0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(summarize(new_text[2], words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "43ba29a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(summarize(new_text[3], words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7e7f3b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summa                         1.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "95178398",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\" Korea introduces new COVID-19 control scheme focused on self-monitoring\n",
    "\n",
    "By Nam Hyun-woo\n",
    "\n",
    "President Moon Jae-in urged Koreans to refrain from \"excessive fear\" over the rapid spread of the Omicron variant and unveiled a new control scheme focused on self-monitoring and self-treatment by infected individuals to free up medical workers to treat severely ill patients.\n",
    "\n",
    "\"After the Omicron variant became the dominant strain in Korea, the number of daily confirmed cases has been setting new highs every day, and it is a grim reality as we are uncertain about how high the number will go and when it will peak,\" Moon said while presiding over a Central Disaster and Safety Countermeasure meeting on Monday.\n",
    "\n",
    "\"We need to be alert, but we don't need to have excessive fear,\" he said. \"Even though the number of confirmed cases increases, if we control severely ill patients, the fatality rate and medical response capability, we can successfully overcome this critical moment.\"\n",
    "\n",
    "Moon's remarks came as the number of daily confirmed cases reached nearly 40,000 amid the rapid spread of the Omicron variant.\n",
    "\n",
    "Korea reported 35,286 new COVID-19 cases on Sunday, pushing up the total caseload to 1.04 million. The COVID-19 situation has been spinning out of control, with the number of daily infected cases reaching a record high of 38,691 on Saturday, up from 18,341 on Monday and 27,443 on Thursday. The rate of positive COVID-19 test results increased from 9.4 percent on Monday to 26 percent on Sunday.\n",
    "\n",
    "Korea Disease Control and Prevention Agency Commissioner Jeong Eun-kyeong said Monday this trajectory is expected to continue for the time being and the daily tally may rise further to somewhere between 130,000 and 170,000 at the end of this month.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "edd82287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(summarize(a, words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ac4c93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88e49483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Just before Neo passes out Morpheus says to him, \"Welcome to the real world.\"\n",
      "He asks Trinity why, if Morpheus thinks Neo is the One, he hasn't taken him to see the Oracle yet.\n",
      "\"What are you trying to tell me,\" asks Neo, \"That I can dodge bullets?\" \"When you're ready,\" Morpheus says, \"You won't have to.\" Just then Morpheus gets a phone call.\n",
      "Cypher asks Neo if Morpheus has told him why he's here.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Morpheus, who is above Neo in the walls, breaks through the wall and lands on the agent, yelling to Trinity to get Neo out of the building.\n",
      "Neo says he only knows that he can bring Morpheus out.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n",
      "Neo tries to tell him that the Oracle told him the opposite but Morpheus says, \"She told you exactly what you needed to hear.\" They call Tank, who tells them of an exit in a subway near them.\n",
      "Trinity reminds Morpheus that they can't use the EMP while Neo is in the Matrix.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c88d8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '''\n",
    "As the blockchain technology attracts attention, interest in cryptocurrency that is received as a reward is also increasing. Currently, investments and transactions are continuing with the expectation and increasing value of cryptocurrency. Accordingly, prediction for cryptocurrency price has been attempted through artificial intelligence technology and social sentiment analysis. The purpose of this paper is to develop a deep learning ensemble model for predicting the price fluctuations and one-day lag price of cryptocurrency based on the design science research method. This paper intends to perform predictive modeling on Ethereum among cryptocurrencies to make predictions more efficiently and accurately than existing models. Therefore, it collects data for five years related to Ethereum price and performs pre-processing through customized functions. In the model development stage, four LSTM models, which are efficient for time series data processing, are utilized to build an ensemble model with the optimal combination of hyperparameters found in the experimental process. Then, based on the performance evaluation scale, the superiority of the model is evaluated through comparison with other deep learning models. The results of this paper have a practical contribution that can be used as a model that shows high performance and predictive rate for cryptocurrency price prediction and price fluctuations. Besides, it shows academic contribution in that it improves the quality of research by following scientific design research procedures that solve scientific problems and create and evaluate new and innovative products in the field of information systems\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "abd4565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(summarize(c, words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3519cfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35932"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4dcd3536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1679"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5e3dcbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1748"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a247bc",
   "metadata": {},
   "source": [
    "아무래도 요약은 최고 10000자 이상이어야 정상적으로 작동하는가 싶다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "28a9ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = '''\n",
    "Convolutional Neural Networks (CNNs / ConvNets)\n",
    "Convolutional Neural Networks are very similar to ordinary Neural Networks from the previous chapter: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply.\n",
    "\n",
    "So what changes? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.\n",
    "\n",
    "\n",
    "Architecture Overview\n",
    "Recall: Regular Neural Nets. As we saw in the previous chapter, Neural Networks receive an input (a single vector), and transform it through a series of hidden layers. Each hidden layer is made up of a set of neurons, where each neuron is fully connected to all neurons in the previous layer, and where neurons in a single layer function completely independently and do not share any connections. The last fully-connected layer is called the “output layer” and in classification settings it represents the class scores.\n",
    "\n",
    "Regular Neural Nets don’t scale well to full images. In CIFAR-10, images are only of size 32x32x3 (32 wide, 32 high, 3 color channels), so a single fully-connected neuron in a first hidden layer of a regular Neural Network would have 32*32*3 = 3072 weights. This amount still seems manageable, but clearly this fully-connected structure does not scale to larger images. For example, an image of more respectable size, e.g. 200x200x3, would lead to neurons that have 200*200*3 = 120,000 weights. Moreover, we would almost certainly want to have several such neurons, so the parameters would add up quickly! Clearly, this full connectivity is wasteful and the huge number of parameters would quickly lead to overfitting.\n",
    "\n",
    "3D volumes of neurons. Convolutional Neural Networks take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height, depth. (Note that the word depth here refers to the third dimension of an activation volume, not to the depth of a full Neural Network, which can refer to the total number of layers in a network.) For example, the input images in CIFAR-10 are an input volume of activations, and the volume has dimensions 32x32x3 (width, height, depth respectively). As we will soon see, the neurons in a layer will only be connected to a small region of the layer before it, instead of all of the neurons in a fully-connected manner. Moreover, the final output layer would for CIFAR-10 have dimensions 1x1x10, because by the end of the ConvNet architecture we will reduce the full image into a single vector of class scores, arranged along the depth dimension. Here is a visualization:\n",
    "\n",
    " \n",
    "Left: A regular 3-layer Neural Network. Right: A ConvNet arranges its neurons in three dimensions (width, height, depth), as visualized in one of the layers. Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations. In this example, the red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be 3 (Red, Green, Blue channels).\n",
    "A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.\n",
    "\n",
    "\n",
    "Layers used to build ConvNets\n",
    "As we described above, a simple ConvNet is a sequence of layers, and every layer of a ConvNet transforms one volume of activations to another through a differentiable function. We use three main types of layers to build ConvNet architectures: Convolutional Layer, Pooling Layer, and Fully-Connected Layer (exactly as seen in regular Neural Networks). We will stack these layers to form a full ConvNet architecture.\n",
    "\n",
    "Example Architecture: Overview. We will go into more details below, but a simple ConvNet for CIFAR-10 classification could have the architecture [INPUT - CONV - RELU - POOL - FC]. In more detail:\n",
    "\n",
    "INPUT [32x32x3] will hold the raw pixel values of the image, in this case an image of width 32, height 32, and with three color channels R,G,B.\n",
    "CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. This may result in volume such as [32x32x12] if we decided to use 12 filters.\n",
    "RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero. This leaves the size of the volume unchanged ([32x32x12]).\n",
    "POOL layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12].\n",
    "FC (i.e. fully-connected) layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score, such as among the 10 categories of CIFAR-10. As with ordinary Neural Networks and as the name implies, each neuron in this layer will be connected to all the numbers in the previous volume.\n",
    "In this way, ConvNets transform the original image layer by layer from the original pixel values to the final class scores. Note that some layers contain parameters and other don’t. In particular, the CONV/FC layers perform transformations that are a function of not only the activations in the input volume, but also of the parameters (the weights and biases of the neurons). On the other hand, the RELU/POOL layers will implement a fixed function. The parameters in the CONV/FC layers will be trained with gradient descent so that the class scores that the ConvNet computes are consistent with the labels in the training set for each image.\n",
    "\n",
    "In summary:\n",
    "\n",
    "A ConvNet architecture is in the simplest case a list of Layers that transform the image volume into an output volume (e.g. holding the class scores)\n",
    "There are a few distinct types of Layers (e.g. CONV/FC/RELU/POOL are by far the most popular)\n",
    "Each Layer accepts an input 3D volume and transforms it to an output 3D volume through a differentiable function\n",
    "Each Layer may or may not have parameters (e.g. CONV/FC do, RELU/POOL don’t)\n",
    "Each Layer may or may not have additional hyperparameters (e.g. CONV/FC/POOL do, RELU doesn’t)\n",
    "\n",
    "The activations of an example ConvNet architecture. The initial volume stores the raw image pixels (left) and the last volume stores the class scores (right). Each volume of activations along the processing path is shown as a column. Since it's difficult to visualize 3D volumes, we lay out each volume's slices in rows. The last layer volume holds the scores for each class, but here we only visualize the sorted top 5 scores, and print the labels of each one. The full web-based demo is shown in the header of our website. The architecture shown here is a tiny VGG Net, which we will discuss later.\n",
    "We now describe the individual layers and the details of their hyperparameters and their connectivities.\n",
    "\n",
    "\n",
    "Convolutional Layer\n",
    "The Conv layer is the core building block of a Convolutional Network that does most of the computational heavy lifting.\n",
    "\n",
    "Overview and intuition without brain stuff. Let’s first discuss what the CONV layer computes without brain/neuron analogies. The CONV layer’s parameters consist of a set of learnable filters. Every filter is small spatially (along width and height), but extends through the full depth of the input volume. For example, a typical filter on a first layer of a ConvNet might have size 5x5x3 (i.e. 5 pixels width and height, and 3 because images have depth 3, the color channels). During the forward pass, we slide (more precisely, convolve) each filter across the width and height of the input volume and compute dot products between the entries of the filter and the input at any position. As we slide the filter over the width and height of the input volume we will produce a 2-dimensional activation map that gives the responses of that filter at every spatial position. Intuitively, the network will learn filters that activate when they see some type of visual feature such as an edge of some orientation or a blotch of some color on the first layer, or eventually entire honeycomb or wheel-like patterns on higher layers of the network. Now, we will have an entire set of filters in each CONV layer (e.g. 12 filters), and each of them will produce a separate 2-dimensional activation map. We will stack these activation maps along the depth dimension and produce the output volume.\n",
    "\n",
    "The brain view. If you’re a fan of the brain/neuron analogies, every entry in the 3D output volume can also be interpreted as an output of a neuron that looks at only a small region in the input and shares parameters with all neurons to the left and right spatially (since these numbers all result from applying the same filter).\n",
    "\n",
    "We now discuss the details of the neuron connectivities, their arrangement in space, and their parameter sharing scheme.\n",
    "\n",
    "Local Connectivity. When dealing with high-dimensional inputs such as images, as we saw above it is impractical to connect neurons to all neurons in the previous volume. Instead, we will connect each neuron to only a local region of the input volume. The spatial extent of this connectivity is a hyperparameter called the receptive field of the neuron (equivalently this is the filter size). The extent of the connectivity along the depth axis is always equal to the depth of the input volume. It is important to emphasize again this asymmetry in how we treat the spatial dimensions (width and height) and the depth dimension: The connections are local in 2D space (along width and height), but always full along the entire depth of the input volume.\n",
    "\n",
    "Example 1. For example, suppose that the input volume has size [32x32x3], (e.g. an RGB CIFAR-10 image). If the receptive field (or the filter size) is 5x5, then each neuron in the Conv Layer will have weights to a [5x5x3] region in the input volume, for a total of 5*5*3 = 75 weights (and +1 bias parameter). Notice that the extent of the connectivity along the depth axis must be 3, since this is the depth of the input volume.\n",
    "\n",
    "Example 2. Suppose an input volume had size [16x16x20]. Then using an example receptive field size of 3x3, every neuron in the Conv Layer would now have a total of 3*3*20 = 180 connections to the input volume. Notice that, again, the connectivity is local in 2D space (e.g. 3x3), but full along the input depth (20).\n",
    "\n",
    " \n",
    "Left: An example input volume in red (e.g. a 32x32x3 CIFAR-10 image), and an example volume of neurons in the first Convolutional layer. Each neuron in the convolutional layer is connected only to a local region in the input volume spatially, but to the full depth (i.e. all color channels). Note, there are multiple neurons (5 in this example) along the depth, all looking at the same region in the input: the lines that connect this column of 5 neurons do not represent the weights (i.e. these 5 neurons do not share the same weights, but they are associated with 5 different filters), they just indicate that these neurons are connected to or looking at the same receptive field or region of the input volume, i.e. they share the same receptive field but not the same weights. Right: The neurons from the Neural Network chapter remain unchanged: They still compute a dot product of their weights with the input followed by a non-linearity, but their connectivity is now restricted to be local spatially.\n",
    "Spatial arrangement. We have explained the connectivity of each neuron in the Conv Layer to the input volume, but we haven’t yet discussed how many neurons there are in the output volume or how they are arranged. Three hyperparameters control the size of the output volume: the depth, stride and zero-padding. We discuss these next:\n",
    "\n",
    "First, the depth of the output volume is a hyperparameter: it corresponds to the number of filters we would like to use, each learning to look for something different in the input. For example, if the first Convolutional Layer takes as input the raw image, then different neurons along the depth dimension may activate in presence of various oriented edges, or blobs of color. We will refer to a set of neurons that are all looking at the same region of the input as a depth column (some people also prefer the term fibre).\n",
    "Second, we must specify the stride with which we slide the filter. When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 (or uncommonly 3 or more, though this is rare in practice) then the filters jump 2 pixels at a time as we slide them around. This will produce smaller output volumes spatially.\n",
    "As we will soon see, sometimes it will be convenient to pad the input volume with zeros around the border. The size of this zero-padding is a hyperparameter. The nice feature of zero padding is that it will allow us to control the spatial size of the output volumes (most commonly as we’ll see soon we will use it to exactly preserve the spatial size of the input volume so the input and output width and height are the same).\n",
    "We can compute the spatial size of the output volume as a function of the input volume size (W), the receptive field size of the Conv Layer neurons (F), the stride with which they are applied (S), and the amount of zero padding used (P) on the border. You can convince yourself that the correct formula for calculating how many neurons “fit” is given by (W−F+2P)/S+1. For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output. Lets also see one more graphical example:\n",
    "\n",
    "\n",
    "Illustration of spatial arrangement. In this example there is only one spatial dimension (x-axis), one neuron with a receptive field size of F = 3, the input size is W = 5, and there is zero padding of P = 1. Left: The neuron strided across the input in stride of S = 1, giving output of size (5 - 3 + 2)/1+1 = 5. Right: The neuron uses stride of S = 2, giving output of size (5 - 3 + 2)/2+1 = 3. Notice that stride S = 3 could not be used since it wouldn't fit neatly across the volume. In terms of the equation, this can be determined since (5 - 3 + 2) = 4 is not divisible by 3.\n",
    "The neuron weights are in this example [1,0,-1] (shown on very right), and its bias is zero. These weights are shared across all yellow neurons (see parameter sharing below).\n",
    "Use of zero-padding. In the example above on left, note that the input dimension was 5 and the output dimension was equal: also 5. This worked out so because our receptive fields were 3 and we used zero padding of 1. If there was no zero-padding used, then the output volume would have had spatial dimension of only 3, because that is how many neurons would have “fit” across the original input. In general, setting zero padding to be P=(F−1)/2 when the stride is S=1 ensures that the input volume and output volume will have the same size spatially. It is very common to use zero-padding in this way and we will discuss the full reasons when we talk more about ConvNet architectures.\n",
    "\n",
    "Constraints on strides. Note again that the spatial arrangement hyperparameters have mutual constraints. For example, when the input has size W=10, no zero-padding is used P=0, and the filter size is F=3, then it would be impossible to use stride S=2, since (W−F+2P)/S+1=(10−3+0)/2+1=4.5, i.e. not an integer, indicating that the neurons don’t “fit” neatly and symmetrically across the input. Therefore, this setting of the hyperparameters is considered to be invalid, and a ConvNet library could throw an exception or zero pad the rest to make it fit, or crop the input to make it fit, or something. As we will see in the ConvNet architectures section, sizing the ConvNets appropriately so that all the dimensions “work out” can be a real headache, which the use of zero-padding and some design guidelines will significantly alleviate.\n",
    "\n",
    "Real-world example. The Krizhevsky et al. architecture that won the ImageNet challenge in 2012 accepted images of size [227x227x3]. On the first Convolutional Layer, it used neurons with receptive field size F=11, stride S=4 and no zero padding P=0. Since (227 - 11)/4 + 1 = 55, and since the Conv layer had a depth of K=96, the Conv layer output volume had size [55x55x96]. Each of the 55*55*96 neurons in this volume was connected to a region of size [11x11x3] in the input volume. Moreover, all 96 neurons in each depth column are connected to the same [11x11x3] region of the input, but of course with different weights. As a fun aside, if you read the actual paper it claims that the input images were 224x224, which is surely incorrect because (224 - 11)/4 + 1 is quite clearly not an integer. This has confused many people in the history of ConvNets and little is known about what happened. My own best guess is that Alex used zero-padding of 3 extra pixels that he does not mention in the paper.\n",
    "\n",
    "Parameter Sharing. Parameter sharing scheme is used in Convolutional Layers to control the number of parameters. Using the real-world example above, we see that there are 55*55*96 = 290,400 neurons in the first Conv Layer, and each has 11*11*3 = 363 weights and 1 bias. Together, this adds up to 290400 * 364 = 105,705,600 parameters on the first layer of the ConvNet alone. Clearly, this number is very high.\n",
    "\n",
    "It turns out that we can dramatically reduce the number of parameters by making one reasonable assumption: That if one feature is useful to compute at some spatial position (x,y), then it should also be useful to compute at a different position (x2,y2). In other words, denoting a single 2-dimensional slice of depth as a depth slice (e.g. a volume of size [55x55x96] has 96 depth slices, each of size [55x55]), we are going to constrain the neurons in each depth slice to use the same weights and bias. With this parameter sharing scheme, the first Conv Layer in our example would now have only 96 unique set of weights (one for each depth slice), for a total of 96*11*11*3 = 34,848 unique weights, or 34,944 parameters (+96 biases). Alternatively, all 55*55 neurons in each depth slice will now be using the same parameters. In practice during backpropagation, every neuron in the volume will compute the gradient for its weights, but these gradients will be added up across each depth slice and only update a single set of weights per slice.\n",
    "\n",
    "Notice that if all neurons in a single depth slice are using the same weight vector, then the forward pass of the CONV layer can in each depth slice be computed as a convolution of the neuron’s weights with the input volume (Hence the name: Convolutional Layer). This is why it is common to refer to the sets of weights as a filter (or a kernel), that is convolved with the input.\n",
    "\n",
    "\n",
    "Example filters learned by Krizhevsky et al. Each of the 96 filters shown here is of size [11x11x3], and each one is shared by the 55*55 neurons in one depth slice. Notice that the parameter sharing assumption is relatively reasonable: If detecting a horizontal edge is important at some location in the image, it should intuitively be useful at some other location as well due to the translationally-invariant structure of images. There is therefore no need to relearn to detect a horizontal edge at every one of the 55*55 distinct locations in the Conv layer output volume.\n",
    "Note that sometimes the parameter sharing assumption may not make sense. This is especially the case when the input images to a ConvNet have some specific centered structure, where we should expect, for example, that completely different features should be learned on one side of the image than another. One practical example is when the input are faces that have been centered in the image. You might expect that different eye-specific or hair-specific features could (and should) be learned in different spatial locations. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a Locally-Connected Layer.\n",
    "\n",
    "Numpy examples. To make the discussion above more concrete, lets express the same ideas but in code and with a specific example. Suppose that the input volume is a numpy array X. Then:\n",
    "\n",
    "A depth column (or a fibre) at position (x,y) would be the activations X[x,y,:].\n",
    "A depth slice, or equivalently an activation map at depth d would be the activations X[:,:,d].\n",
    "Conv Layer Example. Suppose that the input volume X has shape X.shape: (11,11,4). Suppose further that we use no zero padding (P=0), that the filter size is F=5, and that the stride is S=2. The output volume would therefore have spatial size (11-5)/2+1 = 4, giving a volume with width and height of 4. The activation map in the output volume (call it V), would then look as follows (only some of the elements are computed in this example):\n",
    "\n",
    "V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0\n",
    "V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0\n",
    "V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0\n",
    "V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0\n",
    "Remember that in numpy, the operation * above denotes elementwise multiplication between the arrays. Notice also that the weight vector W0 is the weight vector of that neuron and b0 is the bias. Here, W0 is assumed to be of shape W0.shape: (5,5,4), since the filter size is 5 and the depth of the input volume is 4. Notice that at each point, we are computing the dot product as seen before in ordinary neural networks. Also, we see that we are using the same weight and bias (due to parameter sharing), and where the dimensions along the width are increasing in steps of 2 (i.e. the stride). To construct a second activation map in the output volume, we would have:\n",
    "\n",
    "V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1\n",
    "V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1\n",
    "V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1\n",
    "V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1\n",
    "V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 (example of going along y)\n",
    "V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 (or along both)\n",
    "where we see that we are indexing into the second depth dimension in V (at index 1) because we are computing the second activation map, and that a different set of parameters (W1) is now used. In the example above, we are for brevity leaving out some of the other operations the Conv Layer would perform to fill the other parts of the output array V. Additionally, recall that these activation maps are often followed elementwise through an activation function such as ReLU, but this is not shown here.\n",
    "\n",
    "Summary. To summarize, the Conv Layer:\n",
    "\n",
    "Accepts a volume of size W1×H1×D1\n",
    "Requires four hyperparameters:\n",
    "Number of filters K,\n",
    "their spatial extent F,\n",
    "the stride S,\n",
    "the amount of zero padding P.\n",
    "Produces a volume of size W2×H2×D2 where:\n",
    "W2=(W1−F+2P)/S+1\n",
    "H2=(H1−F+2P)/S+1 (i.e. width and height are computed equally by symmetry)\n",
    "D2=K\n",
    "With parameter sharing, it introduces F⋅F⋅D1 weights per filter, for a total of (F⋅F⋅D1)⋅K weights and K biases.\n",
    "In the output volume, the d-th depth slice (of size W2×H2) is the result of performing a valid convolution of the d-th filter over the input volume with a stride of S, and then offset by d-th bias.\n",
    "A common setting of the hyperparameters is F=3,S=1,P=1. However, there are common conventions and rules of thumb that motivate these hyperparameters. See the ConvNet architectures section below.\n",
    "\n",
    "Convolution Demo. Below is a running demo of a CONV layer. Since 3D volumes are hard to visualize, all the volumes (the input volume (in blue), the weight volumes (in red), the output volume (in green)) are visualized with each depth slice stacked in rows. The input volume is of size W1=5,H1=5,D1=3, and the CONV layer parameters are K=2,F=3,S=2,P=1. That is, we have two filters of size 3×3, and they are applied with a stride of 2. Therefore, the output volume size has spatial size (5 - 3 + 2)/2 + 1 = 3. Moreover, notice that a padding of P=1 is applied to the input volume, making the outer border of the input volume zero. The visualization below iterates over the output activations (green), and shows that each element is computed by elementwise multiplying the highlighted input (blue) with the filter (red), summing it up, and then offsetting the result by the bias.\n",
    "\n",
    "\n",
    "Implementation as Matrix Multiplication. Note that the convolution operation essentially performs dot products between the filters and local regions of the input. A common implementation pattern of the CONV layer is to take advantage of this fact and formulate the forward pass of a convolutional layer as one big matrix multiply as follows:\n",
    "\n",
    "The local regions in the input image are stretched out into columns in an operation commonly called im2col. For example, if the input is [227x227x3] and it is to be convolved with 11x11x3 filters at stride 4, then we would take [11x11x3] blocks of pixels in the input and stretch each block into a column vector of size 11*11*3 = 363. Iterating this process in the input at stride of 4 gives (227-11)/4+1 = 55 locations along both width and height, leading to an output matrix X_col of im2col of size [363 x 3025], where every column is a stretched out receptive field and there are 55*55 = 3025 of them in total. Note that since the receptive fields overlap, every number in the input volume may be duplicated in multiple distinct columns.\n",
    "The weights of the CONV layer are similarly stretched out into rows. For example, if there are 96 filters of size [11x11x3] this would give a matrix W_row of size [96 x 363].\n",
    "The result of a convolution is now equivalent to performing one large matrix multiply np.dot(W_row, X_col), which evaluates the dot product between every filter and every receptive field location. In our example, the output of this operation would be [96 x 3025], giving the output of the dot product of each filter at each location.\n",
    "The result must finally be reshaped back to its proper output dimension [55x55x96].\n",
    "This approach has the downside that it can use a lot of memory, since some values in the input volume are replicated multiple times in X_col. However, the benefit is that there are many very efficient implementations of Matrix Multiplication that we can take advantage of (for example, in the commonly used BLAS API). Moreover, the same im2col idea can be reused to perform the pooling operation, which we discuss next.\n",
    "\n",
    "Backpropagation. The backward pass for a convolution operation (for both the data and the weights) is also a convolution (but with spatially-flipped filters). This is easy to derive in the 1-dimensional case with a toy example (not expanded on for now).\n",
    "\n",
    "1x1 convolution. As an aside, several papers use 1x1 convolutions, as first investigated by Network in Network. Some people are at first confused to see 1x1 convolutions especially when they come from signal processing background. Normally signals are 2-dimensional so 1x1 convolutions do not make sense (it’s just pointwise scaling). However, in ConvNets this is not the case because one must remember that we operate over 3-dimensional volumes, and that the filters always extend through the full depth of the input volume. For example, if the input is [32x32x3] then doing 1x1 convolutions would effectively be doing 3-dimensional dot products (since the input depth is 3 channels).\n",
    "\n",
    "Dilated convolutions. A recent development (e.g. see paper by Fisher Yu and Vladlen Koltun) is to introduce one more hyperparameter to the CONV layer called the dilation. So far we’ve only discussed CONV filters that are contiguous. However, it’s possible to have filters that have spaces between each cell, called dilation. As an example, in one dimension a filter w of size 3 would compute over input x the following: w[0]*x[0] + w[1]*x[1] + w[2]*x[2]. This is dilation of 0. For dilation 1 the filter would instead compute w[0]*x[0] + w[1]*x[2] + w[2]*x[4]; In other words there is a gap of 1 between the applications. This can be very useful in some settings to use in conjunction with 0-dilated filters because it allows you to merge spatial information across the inputs much more agressively with fewer layers. For example, if you stack two 3x3 CONV layers on top of each other then you can convince yourself that the neurons on the 2nd layer are a function of a 5x5 patch of the input (we would say that the effective receptive field of these neurons is 5x5). If we use dilated convolutions then this effective receptive field would grow much quicker.\n",
    "\n",
    "\n",
    "Pooling Layer\n",
    "It is common to periodically insert a Pooling layer in-between successive Conv layers in a ConvNet architecture. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. The Pooling Layer operates independently on every depth slice of the input and resizes it spatially, using the MAX operation. The most common form is a pooling layer with filters of size 2x2 applied with a stride of 2 downsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations. Every MAX operation would in this case be taking a max over 4 numbers (little 2x2 region in some depth slice). The depth dimension remains unchanged. More generally, the pooling layer:\n",
    "\n",
    "Accepts a volume of size W1×H1×D1\n",
    "Requires two hyperparameters:\n",
    "their spatial extent F,\n",
    "the stride S,\n",
    "Produces a volume of size W2×H2×D2 where:\n",
    "W2=(W1−F)/S+1\n",
    "H2=(H1−F)/S+1\n",
    "D2=D1\n",
    "Introduces zero parameters since it computes a fixed function of the input\n",
    "For Pooling layers, it is not common to pad the input using zero-padding.\n",
    "It is worth noting that there are only two commonly seen variations of the max pooling layer found in practice: A pooling layer with F=3,S=2 (also called overlapping pooling), and more commonly F=2,S=2. Pooling sizes with larger receptive fields are too destructive.\n",
    "\n",
    "General pooling. In addition to max pooling, the pooling units can also perform other functions, such as average pooling or even L2-norm pooling. Average pooling was often used historically but has recently fallen out of favor compared to the max pooling operation, which has been shown to work better in practice.\n",
    "\n",
    " \n",
    "Pooling layer downsamples the volume spatially, independently in each depth slice of the input volume. Left: In this example, the input volume of size [224x224x64] is pooled with filter size 2, stride 2 into output volume of size [112x112x64]. Notice that the volume depth is preserved. Right: The most common downsampling operation is max, giving rise to max pooling, here shown with a stride of 2. That is, each max is taken over 4 numbers (little 2x2 square).\n",
    "Backpropagation. Recall from the backpropagation chapter that the backward pass for a max(x, y) operation has a simple interpretation as only routing the gradient to the input that had the highest value in the forward pass. Hence, during the forward pass of a pooling layer it is common to keep track of the index of the max activation (sometimes also called the switches) so that gradient routing is efficient during backpropagation.\n",
    "\n",
    "Getting rid of pooling. Many people dislike the pooling operation and think that we can get away without it. For example, Striving for Simplicity: The All Convolutional Net proposes to discard the pooling layer in favor of architecture that only consists of repeated CONV layers. To reduce the size of the representation they suggest using larger stride in CONV layer once in a while. Discarding pooling layers has also been found to be important in training good generative models, such as variational autoencoders (VAEs) or generative adversarial networks (GANs). It seems likely that future architectures will feature very few to no pooling layers.\n",
    "\n",
    "\n",
    "Normalization Layer\n",
    "Many types of normalization layers have been proposed for use in ConvNet architectures, sometimes with the intentions of implementing inhibition schemes observed in the biological brain. However, these layers have since fallen out of favor because in practice their contribution has been shown to be minimal, if any. For various types of normalizations, see the discussion in Alex Krizhevsky’s cuda-convnet library API.\n",
    "\n",
    "\n",
    "Fully-connected layer\n",
    "Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can hence be computed with a matrix multiplication followed by a bias offset. See the Neural Network section of the notes for more information.\n",
    "\n",
    "\n",
    "Converting FC layers to CONV layers\n",
    "It is worth noting that the only difference between FC and CONV layers is that the neurons in the CONV layer are connected only to a local region in the input, and that many of the neurons in a CONV volume share parameters. However, the neurons in both layers still compute dot products, so their functional form is identical. Therefore, it turns out that it’s possible to convert between FC and CONV layers:\n",
    "\n",
    "For any CONV layer there is an FC layer that implements the same forward function. The weight matrix would be a large matrix that is mostly zero except for at certain blocks (due to local connectivity) where the weights in many of the blocks are equal (due to parameter sharing).\n",
    "Conversely, any FC layer can be converted to a CONV layer. For example, an FC layer with K=4096 that is looking at some input volume of size 7×7×512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096. In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will simply be 1×1×4096 since only a single depth column “fits” across the input volume, giving identical result as the initial FC layer.\n",
    "FC->CONV conversion. Of these two conversions, the ability to convert an FC layer to a CONV layer is particularly useful in practice. Consider a ConvNet architecture that takes a 224x224x3 image, and then uses a series of CONV layers and POOL layers to reduce the image to an activations volume of size 7x7x512 (in an AlexNet architecture that we’ll see later, this is done by use of 5 pooling layers that downsample the input spatially by a factor of two each time, making the final spatial size 224/2/2/2/2/2 = 7). From there, an AlexNet uses two FC layers of size 4096 and finally the last FC layers with 1000 neurons that compute the class scores. We can convert each of these three FC layers to CONV layers as described above:\n",
    "\n",
    "Replace the first FC layer that looks at [7x7x512] volume with a CONV layer that uses filter size F=7, giving output volume [1x1x4096].\n",
    "Replace the second FC layer with a CONV layer that uses filter size F=1, giving output volume [1x1x4096]\n",
    "Replace the last FC layer similarly, with F=1, giving final output [1x1x1000]\n",
    "Each of these conversions could in practice involve manipulating (e.g. reshaping) the weight matrix W in each FC layer into CONV layer filters. It turns out that this conversion allows us to “slide” the original ConvNet very efficiently across many spatial positions in a larger image, in a single forward pass.\n",
    "\n",
    "For example, if 224x224 image gives a volume of size [7x7x512] - i.e. a reduction by 32, then forwarding an image of size 384x384 through the converted architecture would give the equivalent volume in size [12x12x512], since 384/32 = 12. Following through with the next 3 CONV layers that we just converted from FC layers would now give the final volume of size [6x6x1000], since (12 - 7)/1 + 1 = 6. Note that instead of a single vector of class scores of size [1x1x1000], we’re now getting an entire 6x6 array of class scores across the 384x384 image.\n",
    "\n",
    "Evaluating the original ConvNet (with FC layers) independently across 224x224 crops of the 384x384 image in strides of 32 pixels gives an identical result to forwarding the converted ConvNet one time.\n",
    "\n",
    "Naturally, forwarding the converted ConvNet a single time is much more efficient than iterating the original ConvNet over all those 36 locations, since the 36 evaluations share computation. This trick is often used in practice to get better performance, where for example, it is common to resize an image to make it bigger, use a converted ConvNet to evaluate the class scores at many spatial positions and then average the class scores.\n",
    "\n",
    "Lastly, what if we wanted to efficiently apply the original ConvNet over the image but at a stride smaller than 32 pixels? We could achieve this with multiple forward passes. For example, note that if we wanted to use a stride of 16 pixels we could do so by combining the volumes received by forwarding the converted ConvNet twice: First over the original image and second over the image but with the image shifted spatially by 16 pixels along both width and height.\n",
    "\n",
    "An IPython Notebook on Net Surgery shows how to perform the conversion in practice, in code (using Caffe)\n",
    "\n",
    "ConvNet Architectures\n",
    "We have seen that Convolutional Networks are commonly made up of only three layer types: CONV, POOL (we assume Max pool unless stated otherwise) and FC (short for fully-connected). We will also explicitly write the RELU activation function as a layer, which applies elementwise non-linearity. In this section we discuss how these are commonly stacked together to form entire ConvNets.\n",
    "\n",
    "\n",
    "Layer Patterns\n",
    "The most common form of a ConvNet architecture stacks a few CONV-RELU layers, follows them with POOL layers, and repeats this pattern until the image has been merged spatially to a small size. At some point, it is common to transition to fully-connected layers. The last fully-connected layer holds the output, such as the class scores. In other words, the most common ConvNet architecture follows the pattern:\n",
    "\n",
    "INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC\n",
    "\n",
    "where the * indicates repetition, and the POOL? indicates an optional pooling layer. Moreover, N >= 0 (and usually N <= 3), M >= 0, K >= 0 (and usually K < 3). For example, here are some common ConvNet architectures you may see that follow this pattern:\n",
    "\n",
    "INPUT -> FC, implements a linear classifier. Here N = M = K = 0.\n",
    "INPUT -> CONV -> RELU -> FC\n",
    "INPUT -> [CONV -> RELU -> POOL]*2 -> FC -> RELU -> FC. Here we see that there is a single CONV layer between every POOL layer.\n",
    "INPUT -> [CONV -> RELU -> CONV -> RELU -> POOL]*3 -> [FC -> RELU]*2 -> FC Here we see two CONV layers stacked before every POOL layer. This is generally a good idea for larger and deeper networks, because multiple stacked CONV layers can develop more complex features of the input volume before the destructive pooling operation.\n",
    "Prefer a stack of small filter CONV to one large receptive field CONV layer. Suppose that you stack three 3x3 CONV layers on top of each other (with non-linearities in between, of course). In this arrangement, each neuron on the first CONV layer has a 3x3 view of the input volume. A neuron on the second CONV layer has a 3x3 view of the first CONV layer, and hence by extension a 5x5 view of the input volume. Similarly, a neuron on the third CONV layer has a 3x3 view of the 2nd CONV layer, and hence a 7x7 view of the input volume. Suppose that instead of these three layers of 3x3 CONV, we only wanted to use a single CONV layer with 7x7 receptive fields. These neurons would have a receptive field size of the input volume that is identical in spatial extent (7x7), but with several disadvantages. First, the neurons would be computing a linear function over the input, while the three stacks of CONV layers contain non-linearities that make their features more expressive. Second, if we suppose that all the volumes have C channels, then it can be seen that the single 7x7 CONV layer would contain C×(7×7×C)=49C2 parameters, while the three 3x3 CONV layers would only contain 3×(C×(3×3×C))=27C2 parameters. Intuitively, stacking CONV layers with tiny filters as opposed to having one CONV layer with big filters allows us to express more powerful features of the input, and with fewer parameters. As a practical disadvantage, we might need more memory to hold all the intermediate CONV layer results if we plan to do backpropagation.\n",
    "\n",
    "Recent departures. It should be noted that the conventional paradigm of a linear list of layers has recently been challenged, in Google’s Inception architectures and also in current (state of the art) Residual Networks from Microsoft Research Asia. Both of these (see details below in case studies section) feature more intricate and different connectivity structures.\n",
    "\n",
    "In practice: use whatever works best on ImageNet. If you’re feeling a bit of a fatigue in thinking about the architectural decisions, you’ll be pleased to know that in 90% or more of applications you should not have to worry about these. I like to summarize this point as “don’t be a hero”: Instead of rolling your own architecture for a problem, you should look at whatever architecture currently works best on ImageNet, download a pretrained model and finetune it on your data. You should rarely ever have to train a ConvNet from scratch or design one from scratch. I also made this point at the Deep Learning school.\n",
    "\n",
    "\n",
    "Layer Sizing Patterns\n",
    "Until now we’ve omitted mentions of common hyperparameters used in each of the layers in a ConvNet. We will first state the common rules of thumb for sizing the architectures and then follow the rules with a discussion of the notation:\n",
    "\n",
    "The input layer (that contains the image) should be divisible by 2 many times. Common numbers include 32 (e.g. CIFAR-10), 64, 96 (e.g. STL-10), or 224 (e.g. common ImageNet ConvNets), 384, and 512.\n",
    "\n",
    "The conv layers should be using small filters (e.g. 3x3 or at most 5x5), using a stride of S=1, and crucially, padding the input volume with zeros in such way that the conv layer does not alter the spatial dimensions of the input. That is, when F=3, then using P=1 will retain the original size of the input. When F=5, P=2. For a general F, it can be seen that P=(F−1)/2 preserves the input size. If you must use bigger filter sizes (such as 7x7 or so), it is only common to see this on the very first conv layer that is looking at the input image.\n",
    "\n",
    "The pool layers are in charge of downsampling the spatial dimensions of the input. The most common setting is to use max-pooling with 2x2 receptive fields (i.e. F=2), and with a stride of 2 (i.e. S=2). Note that this discards exactly 75% of the activations in an input volume (due to downsampling by 2 in both width and height). Another slightly less common setting is to use 3x3 receptive fields with a stride of 2, but this makes “fitting” more complicated (e.g., a 32x32x3 layer would require zero padding to be used with a max-pooling layer with 3x3 receptive field and stride 2). It is very uncommon to see receptive field sizes for max pooling that are larger than 3 because the pooling is then too lossy and aggressive. This usually leads to worse performance.\n",
    "\n",
    "Reducing sizing headaches. The scheme presented above is pleasing because all the CONV layers preserve the spatial size of their input, while the POOL layers alone are in charge of down-sampling the volumes spatially. In an alternative scheme where we use strides greater than 1 or don’t zero-pad the input in CONV layers, we would have to very carefully keep track of the input volumes throughout the CNN architecture and make sure that all strides and filters “work out”, and that the ConvNet architecture is nicely and symmetrically wired.\n",
    "\n",
    "Why use stride of 1 in CONV? Smaller strides work better in practice. Additionally, as already mentioned stride 1 allows us to leave all spatial down-sampling to the POOL layers, with the CONV layers only transforming the input volume depth-wise.\n",
    "\n",
    "Why use padding? In addition to the aforementioned benefit of keeping the spatial sizes constant after CONV, doing this actually improves performance. If the CONV layers were to not zero-pad the inputs and only perform valid convolutions, then the size of the volumes would reduce by a small amount after each CONV, and the information at the borders would be “washed away” too quickly.\n",
    "\n",
    "Compromising based on memory constraints. In some cases (especially early in the ConvNet architectures), the amount of memory can build up very quickly with the rules of thumb presented above. For example, filtering a 224x224x3 image with three 3x3 CONV layers with 64 filters each and padding 1 would create three activation volumes of size [224x224x64]. This amounts to a total of about 10 million activations, or 72MB of memory (per image, for both activations and gradients). Since GPUs are often bottlenecked by memory, it may be necessary to compromise. In practice, people prefer to make the compromise at only the first CONV layer of the network. For example, one compromise might be to use a first CONV layer with filter sizes of 7x7 and stride of 2 (as seen in a ZF net). As another example, an AlexNet uses filter sizes of 11x11 and stride of 4.\n",
    "\n",
    "\n",
    "Case studies\n",
    "There are several architectures in the field of Convolutional Networks that have a name. The most common are:\n",
    "\n",
    "LeNet. The first successful applications of Convolutional Networks were developed by Yann LeCun in 1990’s. Of these, the best known is the LeNet architecture that was used to read zip codes, digits, etc.\n",
    "AlexNet. The first work that popularized Convolutional Networks in Computer Vision was the AlexNet, developed by Alex Krizhevsky, Ilya Sutskever and Geoff Hinton. The AlexNet was submitted to the ImageNet ILSVRC challenge in 2012 and significantly outperformed the second runner-up (top 5 error of 16% compared to runner-up with 26% error). The Network had a very similar architecture to LeNet, but was deeper, bigger, and featured Convolutional Layers stacked on top of each other (previously it was common to only have a single CONV layer always immediately followed by a POOL layer).\n",
    "ZF Net. The ILSVRC 2013 winner was a Convolutional Network from Matthew Zeiler and Rob Fergus. It became known as the ZFNet (short for Zeiler & Fergus Net). It was an improvement on AlexNet by tweaking the architecture hyperparameters, in particular by expanding the size of the middle convolutional layers and making the stride and filter size on the first layer smaller.\n",
    "GoogLeNet. The ILSVRC 2014 winner was a Convolutional Network from Szegedy et al. from Google. Its main contribution was the development of an Inception Module that dramatically reduced the number of parameters in the network (4M, compared to AlexNet with 60M). Additionally, this paper uses Average Pooling instead of Fully Connected layers at the top of the ConvNet, eliminating a large amount of parameters that do not seem to matter much. There are also several followup versions to the GoogLeNet, most recently Inception-v4.\n",
    "VGGNet. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the VGGNet. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end. Their pretrained model is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M). Most of these parameters are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters.\n",
    "ResNet. Residual Network developed by Kaiming He et al. was the winner of ILSVRC 2015. It features special skip connections and a heavy use of batch normalization. The architecture is also missing fully connected layers at the end of the network. The reader is also referred to Kaiming’s presentation (video, slides), and some recent experiments that reproduce these networks in Torch. ResNets are currently by far state of the art Convolutional Neural Network models and are the default choice for using ConvNets in practice (as of May 10, 2016). In particular, also see more recent developments that tweak the original architecture from Kaiming He et al. Identity Mappings in Deep Residual Networks (published March 2016).\n",
    "VGGNet in detail. Lets break down the VGGNet in more detail as a case study. The whole VGGNet is composed of CONV layers that perform 3x3 convolutions with stride 1 and pad 1, and of POOL layers that perform 2x2 max pooling with stride 2 (and no padding). We can write out the size of the representation at each step of the processing and keep track of both the representation size and the total number of weights:\n",
    "\n",
    "INPUT: [224x224x3]        memory:  224*224*3=150K   weights: 0\n",
    "CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*3)*64 = 1,728\n",
    "CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*64)*64 = 36,864\n",
    "POOL2: [112x112x64]  memory:  112*112*64=800K   weights: 0\n",
    "CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*64)*128 = 73,728\n",
    "CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*128)*128 = 147,456\n",
    "POOL2: [56x56x128]  memory:  56*56*128=400K   weights: 0\n",
    "CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*128)*256 = 294,912\n",
    "CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824\n",
    "CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824\n",
    "POOL2: [28x28x256]  memory:  28*28*256=200K   weights: 0\n",
    "CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*256)*512 = 1,179,648\n",
    "CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296\n",
    "CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296\n",
    "POOL2: [14x14x512]  memory:  14*14*512=100K   weights: 0\n",
    "CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\n",
    "CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\n",
    "CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\n",
    "POOL2: [7x7x512]  memory:  7*7*512=25K  weights: 0\n",
    "FC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 = 102,760,448\n",
    "FC: [1x1x4096]  memory:  4096  weights: 4096*4096 = 16,777,216\n",
    "FC: [1x1x1000]  memory:  1000 weights: 4096*1000 = 4,096,000\n",
    "\n",
    "TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)\n",
    "TOTAL params: 138M parameters\n",
    "As is common with Convolutional Networks, notice that most of the memory (and also compute time) is used in the early CONV layers, and that most of the parameters are in the last FC layers. In this particular case, the first FC layer contains 100M weights, out of a total of 140M.\n",
    "\n",
    "\n",
    "Computational Considerations\n",
    "The largest bottleneck to be aware of when constructing ConvNet architectures is the memory bottleneck. Many modern GPUs have a limit of 3/4/6GB memory, with the best GPUs having about 12GB of memory. There are three major sources of memory to keep track of:\n",
    "\n",
    "From the intermediate volume sizes: These are the raw number of activations at every layer of the ConvNet, and also their gradients (of equal size). Usually, most of the activations are on the earlier layers of a ConvNet (i.e. first Conv Layers). These are kept around because they are needed for backpropagation, but a clever implementation that runs a ConvNet only at test time could in principle reduce this by a huge amount, by only storing the current activations at any layer and discarding the previous activations on layers below.\n",
    "From the parameter sizes: These are the numbers that hold the network parameters, their gradients during backpropagation, and commonly also a step cache if the optimization is using momentum, Adagrad, or RMSProp. Therefore, the memory to store the parameter vector alone must usually be multiplied by a factor of at least 3 or so.\n",
    "Every ConvNet implementation has to maintain miscellaneous memory, such as the image data batches, perhaps their augmented versions, etc.\n",
    "Once you have a rough estimate of the total number of values (for activations, gradients, and misc), the number should be converted to size in GB. Take the number of values, multiply by 4 to get the raw number of bytes (since every floating point is 4 bytes, or maybe by 8 for double precision), and then divide by 1024 multiple times to get the amount of memory in KB, MB, and finally GB. If your network doesn’t fit, a common heuristic to “make it fit” is to decrease the batch size, since most of the memory is usually consumed by the activations.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "023560f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52962"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4af2709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the receptive field (or the filter size) is 5x5, then each neuron in the Conv Layer will have weights to a [5x5x3] region in the input volume, for a total of 5*5*3 = 75 weights (and +1 bias parameter).\n"
     ]
    }
   ],
   "source": [
    "print(summarize(d, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2d8bc",
   "metadata": {},
   "source": [
    "### 의외로 긴 문장에선 성공적으로 요약을 한거 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413351be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "추출 요약 : upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "헤드라인 : upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "원문 : Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "추출 요약 : \n",
      "헤드라인 : Delhi techie wins free food from Swiggy for one year on CRED\n",
      "원문 : New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "추출 요약 : The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "헤드라인 : New Zealand end Rohit Sharma-led India's 12-match winning streak\n",
      "원문 : With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢ÂÂ¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.\n",
      "추출 요약 : \n",
      "헤드라인 : Aegon life iTerm insurance plan helps customers save tax\n",
      "원문 : Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman. But in this case, we need to reserve our judgment,\" she added. Hirani has been accused by an assistant who worked in 'Sanju'.\n",
      "추출 요약 : \n",
      "헤드라인 : Have known Hirani for yrs, what if MeToo claims are not true: Sonam\n",
      "원문 : Pakistani singer Rahat Fateh Ali Khan has denied receiving any notice from the Enforcement Directorate over allegedly smuggling foreign currency out of India. \"It would have been better if the authorities would have served the notice first if any and then publicised this,\" reads a press release issued on behalf of Rahat. The statement further called the allegation \"bizarre\".\n",
      "추출 요약 : \n",
      "헤드라인 : Rahat Fateh Ali Khan denies getting notice for smuggling currency\n",
      "원문 : India recorded their lowest ODI total in New Zealand after getting all out for 92 runs in 30.5 overs in the fourth ODI at Hamilton on Thursday. Seven of India's batsmen were dismissed for single-digit scores, while their number ten batsman Yuzvendra Chahal top-scored with 18*(37). India's previous lowest ODI total in New Zealand was 108.\n",
      "추출 요약 : India's previous lowest ODI total in New Zealand was 108.\n",
      "헤드라인 : India get all out for 92, their lowest ODI total in New Zealand\n",
      "원문 : Weeks after ex-CBI Director Alok Verma told the Department of Personnel and Training to consider him retired, the Home Ministry asked him to join work on the last day of his fixed tenure as Director on Thursday. The ministry directed him to immediately join as DG, Fire Services, the post he was transferred to after his removal as CBI chief.\n",
      "추출 요약 : \n",
      "헤드라인 : Govt directs Alok Verma to join work 1 day before his retirement\n",
      "원문 : Andhra Pradesh CM N Chandrababu Naidu has said, \"When I met then US President Bill Clinton, I addressed him as Mr Clinton, not as 'sir'. (PM Narendra) Modi is my junior in politics...I addressed him as sir 10 times.\" \"I did this...to satisfy his ego in the hope that he will do justice to the state,\" he added.\n",
      "추출 요약 : \n",
      "헤드라인 : Called PM Modi 'sir' 10 times to satisfy his ego: Andhra CM\n",
      "원문 : Congress candidate Shafia Zubair won the Ramgarh Assembly seat in Rajasthan, by defeating BJP's Sukhwant Singh with a margin of 12,228 votes in the bypoll. With this victory, Congress has taken its total to 100 seats in the 200-member assembly. The election to the Ramgarh seat was delayed due to the death of sitting MLA and BSP candidate Laxman Singh.\n",
      "추출 요약 : \n",
      "헤드라인 : Cong wins Ramgarh bypoll in Rajasthan, takes total to 100 seats\n",
      "원문 : Two minor cousins in Uttar Pradesh's Gorakhpur were allegedly repeatedly burnt with tongs and forced to eat human excreta by their family for being friends with two boys from the same school. The cousins revealed their ordeal to the police and Child Welfare Committee after being brought back to Gorakhpur from Nepal, where they had fled to escape the torture.\n",
      "추출 요약 : \n",
      "헤드라인 : UP cousins fed human excreta for friendship with boys\n",
      "원문 : Isha Ghosh, an 81-year-old member of Bharat Scouts and Guides (BSG), has been imparting physical and mental training to schoolchildren in Jharkhand for several decades. Chaibasa-based Ghosh reportedly walks seven kilometres daily and spends eight hours conducting physical training, apart from climbing and yoga sessions. She says, \"One should do something for society till one's last breath.\"\n",
      "추출 요약 : \n",
      "헤드라인 : 81-yr-old woman conducts physical training in J'khand schools\n",
      "원문 : Urging saints and seers at the Kumbh Mela to quit smoking, Yoga guru Ramdev said, \"We follow Ram and Krishna who never smoked in their life then why should we?\" Making them take a pledge to quit tobacco, he collected chillum (clay pipe) from several sadhus. He said he will deposit the chillums for display at a museum he'll build.\n",
      "추출 요약 : \n",
      "헤드라인 : Ram, Krishna didn't smoke, why should we: Ramdev to sadhus at Kumbh\n",
      "원문 : Former stripper and regional sales director of a pharmaceutical company, Sunrise Lee, gave a doctor a lap dance in a nightclub to persuade him to prescribe an addictive fentanyl spray in 2012, the company's sales representative told a US court. She said she saw Lee \"sitting on [doctor's] lap, kind of bouncing around.\" Lee has been accused of bribing doctors.\n",
      "추출 요약 : \n",
      "헤드라인 : Pharma exec gave doctor a lap dance to sell medicine in US: Witness\n",
      "원문 : Reliance Industries' Chairman Mukesh Ambani's daughter Isha Ambani, who got married last month, said she only cried at her 'bidaai' because she felt peer pressure as everyone was crying, especially her parents. \"I was emotional too but everyone around me would cry all the time,\" she added. \"It was a very emotional affair for everyone in my family,\" said Isha.\n",
      "추출 요약 : \"It was a very emotional affair for everyone in my family,\" said Isha.\n",
      "헤드라인 :  I only cried at my 'bidaai' as I felt peer pressure: Isha Ambani\n",
      "원문 : Louis Vuitton owner LVMH, which makes high-end beverages like MoÃÂ«t & Chandon champagne and Hennessy cognac, said it's stockpiling four months' worth of wine and spirits in UK in preparation for Brexit. \"We're ready for worst case scenario if there are difficulties with deliveries,\" the French luxury giant said. The UK is scheduled to leave the EU on March 29.\n",
      "추출 요약 : \n",
      "헤드라인 : Louis Vuitton owner to stockpile 4 months of wine, spirits in UK\n",
      "원문 : Filmmaker Karan Johar and actress Tabu turned showstoppers for Gaurav Gupta on the opening night of LakmÃÂ© Fashion Week Summer/ Resort 2019. While Johar wore a red sequinned jacket with black pants, Tabu walked the ramp in a grey embellished gown. The fashion show, which began on January 29, will continue till February 3.\n",
      "추출 요약 : \n",
      "헤드라인 : Karan Johar, Tabu turn showstoppers on opening night of LFW\n",
      "원문 : In a jibe at Congress President Rahul Gandhi, PM Narendra Modi on Wednesday said those on \"bail will have to go to jail.\" PM Modi added, \"He is out on bail and his associates too are facing charges...I know they will be convicted one day.\" The PM claimed he'd waged a war on corruption because he's from a common household. \n",
      "추출 요약 : \n",
      "헤드라인 : Those on bail will go to jail: PM Modi takes jibe at Rahul\n",
      "원문 : Days after he threatened to step down from his post if Congress MLAs continue \"crossing the line,\" Karnataka Chief Minister HD Kumaraswamy accused them of taking potshots and asked, \"How many more days can I tolerate such stuff?\" Kumaraswamy, who made the statements after a Congress MLA demanded that Siddaramaiah be made CM again, said, \"Power is ephemeral.\"\n",
      "추출 요약 : \n",
      "헤드라인 : How long can I tolerate Congress leaders' potshots: K'taka CM\n",
      "원문 : Union Minister Dharmendra Pradhan on Wednesday claimed the illegal mining mafia in Odisha operates under the control of CM Naveen Patnaik and state Congress chief Niranjan Patnaik. He added, \"The time has come for the people of Odisha to put a full stop to their activities...The time has come for us to ask for an explanation from this corrupt government.\"\n",
      "추출 요약 : \n",
      "헤드라인 : Odisha CM Patnaik controls mining mafia: Union Minister\n",
      "원문 : Claiming there is a dearth of ideas among opposition parties, Prime Minister Narendra Modi on Wednesday said, \"The opposition talks only about Modi the whole day, I suspect they even dream about me.\" PM Modi, who was addressing the New India Youth Conclave inÃ¢ÂÂ Surat, added that the opposition parties have only one agenda which is \"Modi\". \n",
      "추출 요약 : \n",
      "헤드라인 : I think the opposition even dreams about me: PM Modi\n",
      "원문 : The Indian Space Research Organisation on Wednesday unveiled Human Space Flight Centre in Bengaluru for its Ã¢ÂÂ¹10,000-crore manned space mission 'Gaganyaan' scheduled for 2021. ISRO said the centre will be responsible for development of engineering systems for crew survival in space and crew selection and training. It'll also pursue activities for sustained human space flight missions, ISRO added.\n",
      "추출 요약 : It'll also pursue activities for sustained human space flight missions, ISRO added.\n",
      "헤드라인 : ISRO unveils Bengaluru centre for manned space mission \n",
      "원문 : At least 12 people have been killed and 170 others have been injured in Saudi Arabia this week due to flooding from heavy rain. The emergency services rescued 271 people from the flooded areas, more than half of them in Tabuk. Heavy rains hit mainly western and northwestern parts of Saudi Arabia, near its border with Jordan.\n",
      "추출 요약 : \n",
      "헤드라인 : 12 killed, 170 injured in Saudi Arabia floods\n",
      "원문 : Reliance Industries' Chairman Mukesh Ambani's daughter Isha Ambani has featured on the cover of the February edition of Vogue India. She's dressed in a white shirt dress and black ruffled skirt by Australian designer Toni Maticevski, while accessorising her look with a Misho ring. In the cover story on her, Isha has spoken about her work and life after marriage.\n",
      " \n",
      "추출 요약 : Reliance Industries' Chairman Mukesh Ambani's daughter Isha Ambani has featured on the cover of the February edition of Vogue India.\n",
      "헤드라인 : Isha Ambani features on February cover of Vogue magazine\n",
      "원문 : Indian Oil Corporation on Wednesday said it's looking for an annual deal to buy US crude as it seeks to broaden oil purchasing options. This comes amid uncertainties over Iran imports. The US had in November granted a six-month waiver to India from sanctions against Iran and restricted the country's monthly intake of Iranian oil to 3,00,000 barrels per day.\n",
      "\n",
      "\n",
      "추출 요약 : \n",
      "헤드라인 : Indian Oil looking for annual deal to buy crude from US\n",
      "원문 : Former Windies fast bowler Curtly Ambrose dismissed seven Australian batsmen within a span of 32 balls giving away just one run, in a Test match on January 30, 1993. Ambrose's spell helped his team bowl out Australia for 119 in the first innings, after being 85 for 2 at one point. Ambrose ended with first-innings figures of 18-9-25-7.\n",
      "추출 요약 : Ambrose ended with first-innings figures of 18-9-25-7.\n",
      "헤드라인 : Pacer once took 7 wickets for just 1 run in 32 balls in a Test\n",
      "원문 : A London zoo is offering people to name a cockroach after their exes on Valentine's Day for ÃÂ£1.50 (nearly Ã¢ÂÂ¹140). \"For those that don't quite require revenge, there's another way to make you feel better about getting back at your ex,\" the zoo said in a statement. The names will appear on zoo's 'roach board' on February 14. \n",
      "추출 요약 : The names will appear on zoo's 'roach board' on February 14.\n",
      "헤드라인 : UK zoo offers people to name cockroach after their ex on Valentine's\n",
      "원문 : Stand-in captain Rohit Sharma has become the 14th Indian cricketer to play 200 ODIs, achieving the feat after taking the field against New Zealand in fourth ODI at Hamilton on Thursday. The 31-year-old had made his ODI debut on June 23, 2007, against Ireland in Belfast. Rohit scored 7,799 runs in his first 199 ODIs at an average of 48.14.\n",
      "추출 요약 : Rohit scored 7,799 runs in his first 199 ODIs at an average of 48.14.\n",
      "헤드라인 : Rohit Sharma becomes 14th Indian cricketer to play 200 ODIs\n",
      "원문 : Batsman Shubman Gill has become the 227th cricketer to represent India in ODI cricket, achieving the feat against New Zealand in the fourth ODI at Hamilton on Thursday. The 19-year-old received his maiden ODI cap from former captain MS Dhoni. Notably, Shubman was named Player of the Under-19 World Cup in New Zealand last year.\n",
      "추출 요약 : Notably, Shubman was named Player of the Under-19 World Cup in New Zealand last year.\n",
      "헤드라인 : 19-year-old Shubman Gill becomes India's 227th ODI cricketer\n",
      "원문 : Investigators searching for a lost plane carrying Argentine forward Emiliano Sala found two seat cushions on French coast that \"likely\" belonged to the aircraft. The investigators said they'll now launch an underwater seabed search for aircraft wreckage. The Cardiff City footballer was travelling from France's Nantes to Wales' Cardiff when his plane disappeared over English Channel on January 21.\n",
      "추출 요약 : \n",
      "헤드라인 : 2 seat cushions from 'missing plane carrying footballer' found\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print('원문 :',new_text[i])\n",
    "    print('추출 요약 :',summarize(new_text[i], words=10))\n",
    "    print('헤드라인 :',data.headlines[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361182d",
   "metadata": {},
   "source": [
    "혹시 몰라서 여러 개의 추출요약을 한 번에 하니까 같은 인덱스도 정상적으로 추출이 가능한 경우가 있었다.\n",
    "이유는 잘 모르겠지만 전처리 과정에서 원본에 뭔가 수정이 가해져서이거나(데이터만 따로 다시 읽어와서 진행함),\n",
    "추출요약이 잘되도록 하는 전처리 과정이 있는데 그것이 생략되었거나 등의 이유가 있을꺼 같다.\n",
    "또한 추출이 정상적으로 일어나는 인덱스와 잘 안나오는 인덱스의 차이를 대조해봐도 특별한 이유를 찾을 수 없었다.\n",
    "\n",
    "\n",
    "추출이 정상적으로 일어나는 경우도 뭔가 맥락을 파악해서 주요 언어만 추출하기보다도\n",
    "원문의 맨 마지막만 앵무새처럼 반복하기만 했는데, 여러 길이의 원문을 넣어서 실험해본 결과로 추측컨대\n",
    "summarize 모듈은 짧은 문맥(뉴스 기사와 같은) 보다는 좀더 긴 내용을 요약하는 용도로 만들어 진거 같다.\n",
    "어느정도 반복되는 단어나 유사한 문맥을 통해 단어나 문장들을 추출하는 형식을 가질 것으로 예상된다.\n",
    "\n",
    "\n",
    "슬프게도 보통 문단의 마지막에 핵심을 다시 환기하여 요약하는 뉴스의 특성상\n",
    "내용적인 측면뿐만 아니라 문법적인 측면에서도 추상적 요약보다 추출적 요약이 더 나은 결과를 보였다.\n",
    "이러면 뉴스를 뒤부터 10단어 슬라이싱 한 것이 추상적 요약, 추출적 요약보다 더 정확하다는 결론이 나온다.\n",
    "\n",
    "\n",
    "뉴스라는 글은 목적성이나 여러 측면에서 일반적인 글과는 다른점이 많으므로, 뉴스 요약에는 기존의 사용하는 모델이아닌\n",
    "뉴스라는 특이점을 잘 살릴 수 있는 학습모델이 필요해 보인다. \n",
    "위에서 말한 전처리 과정도 다르게 해야하는 점도 있고, 헤드라인과 일반 요약이 조금 다르기 때문에 적절한 타겟으로\n",
    "학습이 되었는가도 의문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49f5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
